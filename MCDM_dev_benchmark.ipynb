{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the class DecisionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tabulate as tb\n",
    "\n",
    "\n",
    "# Define the data with more common brand names and some duplicates\n",
    "data = {\n",
    "    \"Bike\": [\"Bike 1\", \"Bike 2\", \"Bike 3\", \"Bike 4\", \"Bike 5\", \"Bike 6\"],\n",
    "    #\"Manufacturer\": [\"Brand A\", \"Brand B\", \"Brand A\", \"Brand C\", \"Brand B\", \"Brand D\"],\n",
    "    \"Cost (CHF)\": [100, 500, 1000, 700, 300, 200],\n",
    "    \"Design (# friends approve)\": [3, 7, 1, 5, 4, 6],\n",
    "    \"Max Speed (km/h)\": [25.1, 42.5, 62, 30, 50, 40],\n",
    "    \"Comfort (Minutes until pain)\": [60, 20, 5, 30, 50, 45],\n",
    "    \"Durability (Years)\": [5, 3, 10, 4, 8, 6]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame as tabular data\n",
    "print('The DataFrame as tabular data:')\n",
    "print(tb.tabulate(df, headers='keys', tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = [\"Cost\", \"Environmental Impact\", \"Social Acceptance\"]\n",
    "weights = helper_weights_AHP(alternatives, method=\"classic\", max_range=9)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = [\"Cost\", \"Environmental Impact\", \"Social Acceptance\"]\n",
    "pairwise_matrix = np.array([[1, 3, 0.5],\n",
    "                            [1/3, 1, 0.25],\n",
    "                            [2, 4, 1]])\n",
    "weights = helper_weights_AHP(alternatives, pairwise_matrix=pairwise_matrix)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = helper_weights_AHP(alternatives, method=\"range\", max_range=8)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCDM.MCDM_dev import DecisionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "metrics_df = df.copy()\n",
    "alt_cols = ['Bike'] # or 'Bike'\n",
    "crit_cols = [\"Cost (CHF)\", \"Design (# friends approve)\", \"Max Speed (km/h)\", \"Comfort (Minutes until pain)\", \"Durability (Years)\"]\n",
    "# Define the objectives\n",
    "objectives = {\n",
    "    \"Cost (CHF)\": -1,  # Minimize\n",
    "    \"Design (# friends approve)\": 1,  # Maximize\n",
    "    \"Max Speed (km/h)\": 1,  # Maximize\n",
    "    \"Comfort (Minutes until pain)\": 1,  # Maximize\n",
    "    \"Durability (Years)\": 1  # Maximize\n",
    "}\n",
    "\n",
    "# Create the DecisionMatrix object\n",
    "dm = DecisionMatrix(metrics_df=metrics_df, alt_cols=alt_cols, crit_cols=crit_cols, objectives=objectives)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.dm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help with generating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def helper_weights_AHP(alternatives):\n",
    "    \"\"\"\n",
    "    This function applies the AHP methodology with a fixed range of 1 to 5,\n",
    "    allowing fractions to represent reciprocal values.\n",
    "    \n",
    "    Parameters:\n",
    "        alternatives (list): A list of alternatives (str) to be evaluated.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with alternatives as keys and their calculated weights as values.\n",
    "    \"\"\"\n",
    "    n = len(alternatives)\n",
    "    pairwise_matrix = np.ones((n, n))  # Initialize the pairwise matrix with 1s (self-comparison)\n",
    "\n",
    "    def get_value(a, b):\n",
    "        \"\"\"\n",
    "        Prompt the user to compare two alternatives with a value between 1 and 5,\n",
    "        where higher values mean greater importance of 'a' over 'b', and fractions (like 1/3) mean 'b' is more important.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                value = input(f\"How much more important is '{a}' compared to '{b}'? (Enter a value from 1 to 5, or a fraction like 1/3): \")\n",
    "                # Allow fractional input as a string (e.g., '1/3')\n",
    "                if \"/\" in value:\n",
    "                    numerator, denominator = map(int, value.split(\"/\"))\n",
    "                    value = numerator / denominator\n",
    "                else:\n",
    "                    value = float(value)\n",
    "                \n",
    "                if 1 <= value <= 5 or (0 < value < 1):\n",
    "                    return value\n",
    "                else:\n",
    "                    print(\"Please enter a value between 1 and 5, or a fraction like 1/3.\")\n",
    "            except (ValueError, ZeroDivisionError):\n",
    "                print(\"Invalid input. Please enter an integer, decimal, or fraction like 1/3.\")\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # Get user input for the comparison\n",
    "            pairwise_matrix[i, j] = get_value(alternatives[i], alternatives[j])\n",
    "            pairwise_matrix[j, i] = 1 / pairwise_matrix[i, j]\n",
    "    \n",
    "    weights = __normalize_and_calculate_weights(pairwise_matrix, alternatives)\n",
    "    \n",
    "    # Check consistency of the matrix\n",
    "    CR = __calculate_consistency_ratio(pairwise_matrix)\n",
    "    if CR >= 0.1:\n",
    "        print(f\"Inconsistency detected: Consistency Ratio (CR) = {CR:.2f}. Consider revising your inputs.\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def __normalize_and_calculate_weights(pairwise_matrix, alternatives):\n",
    "    column_sums = pairwise_matrix.sum(axis=0)\n",
    "    normalized_matrix = pairwise_matrix / column_sums\n",
    "    weights = normalized_matrix.mean(axis=1)\n",
    "    weights_dict = {alternative: round(weight, 4) for alternative, weight in zip(alternatives, weights)}\n",
    "    return weights_dict\n",
    "\n",
    "def __calculate_consistency_ratio(pairwise_matrix):\n",
    "    n = pairwise_matrix.shape[0]\n",
    "    eigenvalues, _ = np.linalg.eig(pairwise_matrix)\n",
    "    max_eigenvalue = max(eigenvalues.real)\n",
    "    CI = (max_eigenvalue - n) / (n - 1)\n",
    "    RI_values = {1: 0, 2: 0, 3: 0.58, 4: 0.9, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}\n",
    "    RI = RI_values.get(n, 1.49)\n",
    "    CR = CI / RI if RI != 0 else 0\n",
    "    return CR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = [\"Cost\", \"Environmental Impact\", \"Social Acceptance\"]\n",
    "weights = helper_weights_AHP(alternatives)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def helper_weights_AHP(alternatives, max_range=9, pairwise_matrix=None, return_matrix=False):\n",
    "    \"\"\"\n",
    "    Calculates weights using the classic AHP approach with optional max range and predefined pairwise matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        alternatives (list): List of alternatives (str) to be evaluated.\n",
    "        max_range (int): Maximum allowable value for pairwise comparison (e.g., 1 to 9 or 1 to 5).\n",
    "        pairwise_matrix (np.ndarray, optional): Predefined pairwise comparison matrix. If not provided, user input is required.\n",
    "        return_matrix (bool): If True, returns both the weights and the pairwise matrix as a DataFrame and raw matrix.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of calculated weights with alternatives as keys.\n",
    "        (optional) pd.DataFrame: Pairwise matrix as a DataFrame if return_matrix is True.\n",
    "        (optional) np.ndarray: Raw pairwise matrix if return_matrix is True.\n",
    "    \"\"\"\n",
    "    n = len(alternatives)\n",
    "    \n",
    "    # If a predefined matrix is provided, clip values to max range\n",
    "    if pairwise_matrix is not None:\n",
    "        pairwise_matrix, clipped = __clip_matrix_to_max_range(pairwise_matrix, max_range)\n",
    "        if clipped:\n",
    "            print(f\"Warning: Some values in the provided matrix exceeded the max range and were clipped to fit within 1/{max_range} to {max_range}.\")\n",
    "    \n",
    "    # If no predefined matrix is given, prompt the user for comparisons\n",
    "    if pairwise_matrix is None:\n",
    "        pairwise_matrix = np.ones((n, n))\n",
    "        \n",
    "        def get_value(a, b):\n",
    "            \"\"\"Prompt user for comparison value within the specified max range.\"\"\"\n",
    "            while True:\n",
    "                try:\n",
    "                    value = input(f\"How much more important is '{a}' compared to '{b}'? (Enter 1 to {max_range} or fraction for reciprocal): \")\n",
    "                    if \"/\" in value:\n",
    "                        numerator, denominator = map(int, value.split(\"/\"))\n",
    "                        value = numerator / denominator\n",
    "                    else:\n",
    "                        value = float(value)\n",
    "                    if 1 <= value <= max_range or (0 < value < 1):\n",
    "                        return value\n",
    "                    else:\n",
    "                        print(f\"Please enter a value between 1 and {max_range} or a fraction.\")\n",
    "                except (ValueError, ZeroDivisionError):\n",
    "                    print(\"Invalid input. Enter an integer or fraction.\")\n",
    "        \n",
    "        # Collect user input for pairwise comparisons\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                pairwise_matrix[i, j] = get_value(alternatives[i], alternatives[j])\n",
    "                pairwise_matrix[j, i] = 1 / pairwise_matrix[i, j]\n",
    "\n",
    "    # Perform final transitivity check after all inputs\n",
    "    inconsistent, example_message = __check_transitivity(pairwise_matrix, alternatives)\n",
    "    if inconsistent:\n",
    "        print(\"Warning: Some logical inconsistencies were detected in the matrix. Consider revisiting certain comparisons.\")\n",
    "        print(f\"For example: {example_message}\")\n",
    "    \n",
    "    # Normalize and calculate weights\n",
    "    weights = __normalize_and_calculate_weights(pairwise_matrix, alternatives)\n",
    "    CR = __calculate_consistency_ratio(pairwise_matrix)\n",
    "\n",
    "    # Final consistency check with CR warning if above threshold\n",
    "    if CR >= 0.1:\n",
    "        print(f\"\\nWarning: Consistency Ratio (CR) = {CR:.2f}, which is above the acceptable threshold of 0.1.\")\n",
    "        print(\"Consider revisiting your pairwise comparisons to improve consistency.\")\n",
    "        print(\"- Use a smaller max range (e.g., 1–5 instead of 1–9) to reduce extreme judgments.\")\n",
    "        print(\"- Re-evaluate any comparisons where values are at the upper end of the range, as these tend to introduce inconsistency.\")\n",
    "        print(\"- Aim for moderate values unless there is a clear and strong preference.\")\n",
    "    \n",
    "    # Return weights and optionally the pairwise matrix as DataFrame and raw matrix\n",
    "    if return_matrix:\n",
    "        # Create DataFrame with \"Alternative\" column and labels for rows/columns\n",
    "        df_matrix = pd.DataFrame(pairwise_matrix, columns=alternatives, index=alternatives)\n",
    "        df_matrix.insert(0, \"Alternative\", alternatives)\n",
    "        return weights, df_matrix, pairwise_matrix\n",
    "    else:\n",
    "        return weights\n",
    "\n",
    "# Function to clip values in the matrix to the specified max range\n",
    "def __clip_matrix_to_max_range(matrix, max_range):\n",
    "    \"\"\"Clip the values of the matrix to fit within the specified max range.\"\"\"\n",
    "    clipped = False\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if i != j:  # Ignore diagonal\n",
    "                if matrix[i, j] > max_range:\n",
    "                    matrix[i, j] = max_range\n",
    "                    matrix[j, i] = 1 / max_range\n",
    "                    clipped = True\n",
    "                elif matrix[i, j] < 1 / max_range:\n",
    "                    matrix[i, j] = 1 / max_range\n",
    "                    matrix[j, i] = max_range\n",
    "                    clipped = True\n",
    "    return matrix, clipped\n",
    "\n",
    "# Function to normalize and calculate weights for AHP\n",
    "def __normalize_and_calculate_weights(pairwise_matrix, alternatives):\n",
    "    column_sums = pairwise_matrix.sum(axis=0)\n",
    "    normalized_matrix = pairwise_matrix / column_sums\n",
    "    weights = normalized_matrix.mean(axis=1)\n",
    "    weights_dict = {alternative: round(weight, 4) for alternative, weight in zip(alternatives, weights)}\n",
    "    return weights_dict\n",
    "\n",
    "# Function to calculate consistency ratio\n",
    "def __calculate_consistency_ratio(pairwise_matrix):\n",
    "    n = pairwise_matrix.shape[0]\n",
    "    eigenvalues, _ = np.linalg.eig(pairwise_matrix)\n",
    "    max_eigenvalue = max(eigenvalues.real)\n",
    "    CI = (max_eigenvalue - n) / (n - 1)\n",
    "    RI_values = {1: 0, 2: 0.58, 3: 0.9, 4: 1.12, 5: 1.24, 6: 1.32, 7: 1.41, 8: 1.45, 9: 1.49, 10: 1.49}\n",
    "    RI = RI_values.get(n, 1.49)\n",
    "    CR = CI / RI if RI != 0 else 0\n",
    "    return CR\n",
    "\n",
    "# Function to check transitivity across the matrix\n",
    "def __check_transitivity(pairwise_matrix, alternatives):\n",
    "    \"\"\"Check the entire matrix for transitivity and return a single inconsistency example if found.\"\"\"\n",
    "    n = len(alternatives)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                if i != j and j != k and i != k:\n",
    "                    implied_value = pairwise_matrix[i, j] * pairwise_matrix[j, k]\n",
    "                    if not np.isclose(implied_value, pairwise_matrix[i, k], atol=0.1):\n",
    "                        # Return a single inconsistency example message\n",
    "                        example_message = (f\"Based on '{alternatives[i]} > {alternatives[j]}' and \"\n",
    "                                           f\"'{alternatives[j]} > {alternatives[k]}', \"\n",
    "                                           f\"'{alternatives[i]} > {alternatives[k]}' should be approximately \"\n",
    "                                           f\"{round(implied_value, 2)}, but is currently \"\n",
    "                                           f\"{round(pairwise_matrix[i, k], 2)}.\")\n",
    "                        return True, example_message\n",
    "    return False, \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = [\"Cost\", \"Quality\", \"Time\", \"More\"]\n",
    "\n",
    "# Use the function and set return_matrix=True\n",
    "weights, df_matrix, raw_matrix = helper_weights_AHP(alternatives, max_range=5, return_matrix=True)\n",
    "\n",
    "# Display weights\n",
    "print(\"Calculated Weights:\", weights)\n",
    "\n",
    "# Display the DataFrame in a table format using tabulate\n",
    "print(\"\\nPairwise Matrix:\")\n",
    "print(tabulate(df_matrix, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "# Display the raw matrix as well (optional)\n",
    "print(\"\\nRaw Pairwise Matrix:\\n\", raw_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the alternatives and the predefined pairwise matrix with an inconsistency\n",
    "alternatives = [\"Cost\", \"Quality\", \"Time\"]\n",
    "pairwise_matrix = np.array([\n",
    "    [1,   2,   6],      # Cost row\n",
    "    [0.5, 1,   3],      # Quality row\n",
    "    [1/6, 1/3, 1]       # Time row\n",
    "])\n",
    "\n",
    "# Calculate the weights using the AHP method\n",
    "weights, df_matrix, raw_matrix = helper_weights_AHP(alternatives, pairwise_matrix=pairwise_matrix, return_matrix=True, max_range=2)\n",
    "\n",
    "# Print the weights and the pairwise matrix\n",
    "print(\"Calculated Weights:\", weights)\n",
    "print(\"\\nPairwise Matrix:\")\n",
    "print(tabulate(df_matrix, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tabulate as tb\n",
    "\n",
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Define the columns for alternatives and criteria\n",
    "alt_cols = [\"Bike\"]\n",
    "crit_cols = [\"Cost (CHF)\", \"Design (# friends approve)\", \"Max Speed (km/h)\", \"Comfort (Minutes until pain)\", \"Durability (Years)\"]\n",
    "\n",
    "# Define weights \n",
    "weights = {\n",
    "    \"Cost (CHF)\": 0.30,\n",
    "    \"Design (# friends approve)\": 0.20,\n",
    "    \"Max Speed (km/h)\": 0.20,\n",
    "    \"Comfort (Minutes until pain)\": 0.10,\n",
    "    \"Durability (Years)\": 0.20\n",
    "}\n",
    "\n",
    "# Define the objectives\n",
    "objectives = {\n",
    "    \"Cost (CHF)\": -1,  # Minimize\n",
    "    \"Design (# friends approve)\": 1,  # Maximize\n",
    "    \"Max Speed (km/h)\": 1,  # Maximize\n",
    "    \"Comfort (Minutes until pain)\": 1,  # Maximize\n",
    "    \"Durability (Years)\": 1  # Maximize\n",
    "}\n",
    "\n",
    "# Define the group columns\n",
    "group_cols = [\"Terrain\"]\n",
    "\n",
    "# Define the group weights\n",
    "group_weights = {\n",
    "    \"Terrain\": {\n",
    "        \"Flat\": 0.5,\n",
    "        \"Hilly\": 0.3,\n",
    "        \"Mountainous\": 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the uncertainty columns\n",
    "unc_cols = []\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "# Sample DataFrame to simulate the decision matrix\n",
    "data = {\n",
    "    \"Bike\": [\"Bike A\", \"Bike A\", \"Bike A\", \"Bike B\", \"Bike B\", \"Bike B\", \"Bike C\", \"Bike C\", \"Bike C\", \"Bike D\", \"Bike D\", \"Bike D\", \"Bike E\", \"Bike E\", \"Bike E\"],\n",
    "    \"Cost (CHF)\": [500, 500, 500, 700, 700, 700, 450, 450, 450, 650, 650, 650, 800, 800, 800],\n",
    "    \"Design (# friends approve)\": [7, 7, 7, 6, 6, 6, 8, 8, 8, 5, 5, 5, 9, 9, 9],\n",
    "    \"Max Speed (km/h)\": [25, 20, 15, 28, 23, 18, 22, 17, 12, 27, 22, 17, 30, 25, 20],\n",
    "    \"Comfort (Minutes until pain)\": [30, 25, 20, 45, 40, 35, 35, 30, 25, 50, 45, 40, 40, 35, 30],\n",
    "    \"Durability (Years)\": [5, 4, 3, 4, 3, 2, 6, 5, 4, 5, 4, 3, 7, 6, 5],\n",
    "    \"Terrain\": [\"Flat\", \"Hilly\", \"Mountainous\"] * 5\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate the decision matrix – Initialize the decision matrix object\n",
    "dm = DecisionMatrix(\n",
    "    metrics_df=df,\n",
    "    objectives=objectives,\n",
    "    alt_cols=alt_cols,\n",
    "    crit_cols=crit_cols,\n",
    "    weights=weights,\n",
    "    group_cols=group_cols,\n",
    "    group_weights=group_weights,\n",
    "    unc_cols=unc_cols\n",
    ")\n",
    "\n",
    "# Display the decision matrix\n",
    "print('The decision matrix:')\n",
    "print(tb.tabulate(dm.dm_df, headers='keys', tablefmt='pretty'))\n",
    "print('')\n",
    "\n",
    "# Print the criteria DataFrame\n",
    "print('The criteria DataFrame:')\n",
    "print(tb.tabulate(dm.crit_df, headers='keys', tablefmt='pretty'))\n",
    "print('')\n",
    "\n",
    "# Print the categorized criteria DataFrame\n",
    "print('The categorized criteria DataFrame:')\n",
    "print(tb.tabulate(dm.cat_crit_df, headers='keys', tablefmt='pretty'))\n",
    "print('')\n",
    "\n",
    "# Print the alternatives DataFrame\n",
    "print('The alternatives DataFrame:')\n",
    "print(tb.tabulate(dm.alternatives_df, headers='keys', tablefmt='pretty'))\n",
    "print('')\n",
    "\n",
    "# Print the groups DataFrame\n",
    "print('The groups DataFrame:')\n",
    "print(tb.tabulate(dm.groups_df, headers='keys', tablefmt='pretty'))\n",
    "print('')\n",
    "\n",
    "# Print the group weights\n",
    "print('The group weights:')\n",
    "print(dm.group_weights)\n",
    "\n",
    "# Plot the criteria\n",
    "dm.plot_criteria(group_by_category=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the pivot column\n",
    "piv_col = \"Terrain\"\n",
    "\n",
    "# Pivot and reweight the criteria based on the specified pivot column\n",
    "dm_grouped = dm.pivot_and_reweight_criteria(piv_col)\n",
    "\n",
    "# Display the pivoted and reweighted decision matrix\n",
    "print('The pivoted and reweighted decision matrix:')\n",
    "print(tb.tabulate(dm_grouped.dm_df, headers='keys', tablefmt='pretty'))\n",
    "print('')\n",
    "\n",
    "# plot the criteria\n",
    "dm_grouped.plot_criteria(group_by_category=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionMatrix:\n",
    "    def __init__(\n",
    "        self,\n",
    "        metrics_df: pd.DataFrame,\n",
    "        objectives: Dict[str, int],\n",
    "        alt_cols: List[str],\n",
    "        crit_cols: List[str],\n",
    "        weights: Optional[Dict[str, float]] = None,\n",
    "        group_cols: Optional[List[str]] = [],\n",
    "        group_weights: Optional[Dict[str, float]] = None,\n",
    "        unc_cols: Optional[List[str]] = [],\n",
    "        crit_cats: Optional[Dict[str, List[str]]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the DecisionMatrix object.\n",
    "\n",
    "        Parameters:\n",
    "        - metrics_df : pd.DataFrame\n",
    "            DataFrame containing metrics data.\n",
    "        - objectives : Dict[str, int]\n",
    "            Dictionary mapping objectives to their values.\n",
    "        - alt_cols : List[str]\n",
    "            List of alternative columns.\n",
    "        - crit_cols : List[str]\n",
    "            List of criteria columns.\n",
    "        - weights : Dict[str, float], optional\n",
    "            Dictionary of criteria weights values. Defaults to an empty dictionary.\n",
    "        - group_cols : List[str], optional\n",
    "            List of group columns. Defaults to an empty list.\n",
    "        - group_weights : Dict[str, float], optional\n",
    "            Dictionary of weights for group columns. Defaults to an empty dictionary.\n",
    "        - unc_cols : List[str], optional\n",
    "            List of uncertainty columns. Defaults to an empty list.\n",
    "        - crit_cats : Dict[str, List[str]], optional\n",
    "            Dictionary of categorized criteria. Defaults to an empty dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Assign input parameters to class attributes as copies\n",
    "        self.metrics_df = metrics_df.copy()\n",
    "        self.objectives = copy.deepcopy(objectives)\n",
    "        self.alt_cols = alt_cols.copy()\n",
    "        self.crit_cols = crit_cols.copy()\n",
    "        self.weights = weights.copy() if weights is not None else {}\n",
    "        self.group_cols = group_cols.copy() if group_cols is not None else []\n",
    "        self.group_weights = group_weights.copy() if group_weights is not None else {}\n",
    "        self.unc_cols = unc_cols.copy() if unc_cols is not None else []\n",
    "        self.crit_cats = crit_cats.copy() if crit_cats is not None else {}\n",
    "\n",
    "        # Initialize dataframes – Attributes to store dataframes used for calculations and organization\n",
    "        self._initialize_dataframes()\n",
    "\n",
    "        # Process initial data\n",
    "        self._process_initial_data()\n",
    "\n",
    "    # Method to initialize dataframes\n",
    "    def _initialize_dataframes(self):\n",
    "        self.dm_df = None # Decision matrix dataframe ( The main dataframe)\n",
    "        self.alternatives_df = None # Alternatives dataframe (unique alternatives, their IDs)\n",
    "        self.crit_df = None # Criteria dataframe (criteria and their weights)\n",
    "        self.cat_crit_df = None # Categorized criteria dataframe (criteria and their categories)\n",
    "        self.groups_df = None # Groups dataframe (if group columns are provided, otherwise None)\n",
    "        self.unc_smpls_df = None # Uncertainty samples dataframe (if uncertainty columns are provided, otherwise None)\n",
    "\n",
    "    # Method to process initial data\n",
    "    def _process_initial_data(self):\n",
    "        self._sort_metrics_df()                # Sort metrics_df by alternative, group, and uncertainty columns for readability in the decision matrix\n",
    "        self._validate_inputs()                # Validate inputs for duplicate rows based on alternative, group, and uncertainty columns\n",
    "        self._calculate_weights()              # Calculate weights for criteria and group columns if not provided\n",
    "        self._prepare_criteria_dataframes()    # Prepare criteria dataframes (criteria and categorized criteria)\n",
    "        self._prepare_alternatives_dataframe() # Prepare alternatives dataframe (unique alternatives)\n",
    "        self._prepare_decision_matrix_dataframe() # Prepare decision matrix dataframe by merging alternatives, groups, and uncertainty samples\n",
    "\n",
    "    # Method to sort metrics dataframe\n",
    "    def _sort_metrics_df(self):\n",
    "        \"\"\"\n",
    "        Sort the metrics DataFrame by alternative, group, and uncertainty columns.\n",
    "        Sorting by alternative, group, and uncertainty columns makes the decision matrix more readable.\n",
    "        \"\"\"\n",
    "        self.metrics_df = self.metrics_df.sort_values(by=self.alt_cols + self.group_cols + self.unc_cols)\n",
    "\n",
    "    # Method to validate inputs\n",
    "    def _validate_inputs(self):\n",
    "        \"\"\"\n",
    "        Validate the input DataFrame for duplicate rows based on alternative, group, and uncertainty columns.\n",
    "        Each alternative could only have one unique combination of group and uncertainty columns.\n",
    "        \"\"\"\n",
    "        if self.metrics_df.duplicated(subset=self.alt_cols + self.group_cols + self.unc_cols, keep=False).any():\n",
    "            raise ValueError(\"Duplicated rows of alt_cols, group_cols, and sample. Some alternative IDs are counted more than once for some group ID and sample ID pairs.\")\n",
    "\n",
    "    # Method to calculate weights\n",
    "    def _calculate_weights(self):\n",
    "        \"\"\"\n",
    "        Calculate weights for criteria and group columns if not provided.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Assign equal weights to criteria if not provided.\n",
    "        2. Calculate and assign weights to group members if group columns are specified.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if weights for criteria are provided\n",
    "        if not self.weights:\n",
    "            # Define a custom rounding function to handle precision\n",
    "            def custom_round(value):\n",
    "                # Determine the number of decimal places\n",
    "                decimal_count = len(str(value).split(\".\")[1]) if \".\" in str(value) else 0\n",
    "                # Round to a maximum of two decimal places\n",
    "                decimals = 2 if decimal_count >= 2 else 1\n",
    "                return round(value, decimals)\n",
    "            \n",
    "            # Assign equal weights to each criterion\n",
    "            self.weights = {crit: custom_round(1/len(self.crit_cols)) for crit in self.crit_cols}\n",
    "\n",
    "        # Check if there are group columns specified\n",
    "        if self.group_cols:\n",
    "            # Drop duplicates to identify unique groups and reset the index\n",
    "            self.groups_df = self.metrics_df[self.group_cols].drop_duplicates().reset_index(drop=True)\n",
    "            # Assign a unique 'Group ID' to each group\n",
    "            self.groups_df.insert(0, 'Group ID', ['G' + str(idx) for idx in range(1, len(self.groups_df) + 1)])\n",
    "            \n",
    "            # Iterate through each group column\n",
    "            for group_col in self.group_cols:\n",
    "                # Create a temporary DataFrame with unique values of the group column\n",
    "                temp_df = pd.DataFrame(self.metrics_df[group_col].drop_duplicates())\n",
    "                # Initialize a 'Weight' column with NaN values\n",
    "                temp_df['Weight'] = np.nan\n",
    "                \n",
    "                # Iterate through each member of the group\n",
    "                for idx, member in temp_df.iterrows():\n",
    "                    member_name = member[group_col]\n",
    "                    # Assign provided group weight if available\n",
    "                    if member_name != 'ALL' and self.group_weights and group_col in self.group_weights and isinstance(self.group_weights[group_col], dict) and member_name in self.group_weights[group_col]:\n",
    "                        temp_df.at[idx, 'Weight'] = self.group_weights[group_col][member_name]\n",
    "                \n",
    "                # Exclude rows where the group column value is 'ALL'\n",
    "                temp_df = temp_df[temp_df[group_col] != 'ALL']\n",
    "                # Calculate the sum of defined weights\n",
    "                sum_defined_weights = temp_df['Weight'].sum()\n",
    "                # Identify members with undefined weights\n",
    "                remaining_members = temp_df[temp_df['Weight'].isna()]\n",
    "                remaining_count = len(remaining_members)\n",
    "                \n",
    "                # Distribute the remaining weight equally among members with undefined weights\n",
    "                if remaining_count > 0:\n",
    "                    remainder = 1 - sum_defined_weights\n",
    "                    equal_weight = remainder / remaining_count\n",
    "                    temp_df.loc[temp_df['Weight'].isna(), 'Weight'] = equal_weight\n",
    "                \n",
    "                # Update the group weights with the calculated weights\n",
    "                self.group_weights[group_col] = temp_df\n",
    "\n",
    "    # Method to prepare criteria dataframes\n",
    "    def _prepare_criteria_dataframes(self):\n",
    "        \"\"\"\n",
    "        Prepare DataFrames for criteria and categorized criteria.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Create a DataFrame for criteria with their IDs, weights, and objectives.\n",
    "        2. Create a dictionary for categorized criteria if not provided.\n",
    "        3. Create a DataFrame for categorized criteria and merge it with the criteria DataFrame.\n",
    "\n",
    "        Steps:\n",
    "        1. Create a DataFrame for criteria:\n",
    "            - Generate criteria IDs.\n",
    "            - Assign criteria weights and objectives.\n",
    "        2. Check if categorized criteria are provided:\n",
    "            - If not, create a default categorization where each criterion is its own category.\n",
    "        3. Create a DataFrame for categorized criteria:\n",
    "            - Assign category IDs.\n",
    "            - Merge categorized criteria with the main criteria DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Create a DataFrame for criteria\n",
    "        self.crit_df = pd.DataFrame([\n",
    "            {'Criteria ID': 'C' + str(idx + 1), 'Criteria': crit, 'Weight': self.weights[crit], 'Objective': self.objectives[crit]}\n",
    "            for idx, crit in enumerate(self.crit_cols)\n",
    "        ])\n",
    "\n",
    "        # Step 2: Check if categorized criteria are provided\n",
    "        if not self.crit_cats:\n",
    "            # Create a default categorization where each criterion is its own category\n",
    "            self.crit_cats = {crit: [crit] for crit in self.crit_cols}\n",
    "\n",
    "        # Step 3: Create a DataFrame for categorized criteria\n",
    "        data = [\n",
    "            {'Cat ID': 'CAT' + str(idx + 1), 'Category': cat, 'Criteria': crit}\n",
    "            for idx, (cat, crits) in enumerate(self.crit_cats.items())\n",
    "            for crit in crits\n",
    "        ]\n",
    "        self.cat_crit_df = pd.DataFrame(data).merge(self.crit_df, on='Criteria')\n",
    "\n",
    "    # Method to prepare alternatives dataframe\n",
    "    def _prepare_alternatives_dataframe(self):\n",
    "        \"\"\"\n",
    "        Prepare the alternatives DataFrame.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Check if alternative columns are provided.\n",
    "        2. Create a DataFrame for unique alternatives.\n",
    "        3. Assign unique IDs to each alternative.\n",
    "\n",
    "        Steps:\n",
    "        1. Check for alternative columns:\n",
    "            - Raise an error if not provided.\n",
    "        2. Create a DataFrame for unique alternatives:\n",
    "            - Drop duplicate rows.\n",
    "        3. Assign unique IDs to each alternative:\n",
    "            - Insert an 'Alternative ID' column with unique IDs.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Check for alternative columns\n",
    "        if not self.alt_cols:\n",
    "            raise ValueError(\"No alternative column given.\")\n",
    "\n",
    "        # Step 2: Create a DataFrame for unique alternatives\n",
    "        self.alternatives_df = self.metrics_df[self.alt_cols].drop_duplicates()\n",
    "\n",
    "        # Step 3: Ensure 'Alternative ID' exists only once\n",
    "        if 'Alternative ID' not in self.alternatives_df.columns:\n",
    "            self.alternatives_df.insert(0, 'Alternative ID', ['A' + str(idx) for idx in range(1, len(self.alternatives_df) + 1)])\n",
    "\n",
    "    # Method to prepare decision matrix dataframe\n",
    "    def _prepare_decision_matrix_dataframe(self):\n",
    "        \"\"\"\n",
    "        Prepare the decision matrix DataFrame by merging alternatives, groups, and uncertainty samples.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Initialize the decision matrix with the alternatives DataFrame.\n",
    "        2. Merge the decision matrix with groups DataFrame if available.\n",
    "        3. Merge the decision matrix with uncertainty samples DataFrame if available.\n",
    "        4. Merge the decision matrix with the metrics DataFrame on specified columns.\n",
    "\n",
    "        Steps:\n",
    "        1. Initialize the decision matrix:\n",
    "            - Copy the alternatives DataFrame.\n",
    "        2. Merge with groups DataFrame:\n",
    "            - If available, merge on a temporary '_merge' column.\n",
    "        3. Merge with uncertainty samples DataFrame:\n",
    "            - If available, merge on a temporary '_merge' column.\n",
    "        4. Finalize the decision matrix:\n",
    "            - Drop the temporary '_merge' column.\n",
    "            - Merge with the metrics DataFrame on alternative, group, and uncertainty columns.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Initialize the decision matrix\n",
    "        self.dm_df = self.alternatives_df.copy()\n",
    "        self.dm_df['_merge'] = 1\n",
    "\n",
    "        # Step 2: Merge with groups DataFrame if available\n",
    "        if isinstance(self.groups_df, pd.DataFrame):\n",
    "            self.groups_df['_merge'] = 1\n",
    "            self.dm_df = self.dm_df.merge(self.groups_df, on='_merge')\n",
    "            self.groups_df = self.groups_df.drop('_merge', axis=1)\n",
    "\n",
    "        # Step 3: Merge with uncertainty samples DataFrame if available\n",
    "        if isinstance(self.unc_smpls_df, pd.DataFrame):\n",
    "            self.unc_smpls_df['_merge'] = 1\n",
    "            self.dm_df = self.dm_df.merge(self.unc_smpls_df, on='_merge')\n",
    "            self.unc_smpls_df = self.unc_smpls_df.drop('_merge', axis=1)\n",
    "\n",
    "        # Step 4: Finalize the decision matrix\n",
    "        self.dm_df = self.dm_df.drop('_merge', axis=1)\n",
    "        self.dm_df = pd.merge(self.dm_df, self.metrics_df[self.alt_cols + self.group_cols + self.unc_cols + self.crit_cols], on=self.alt_cols + self.group_cols + self.unc_cols, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define example data with Terrain and Weather\n",
    "data = {\n",
    "    'Alternative': ['A1', 'A1', 'A1', 'A1', 'A1', 'A1', 'A1', 'A1', 'A1',\n",
    "                    'A2', 'A2', 'A2', 'A2', 'A2', 'A2', 'A2', 'A2', 'A2',\n",
    "                    'A3', 'A3', 'A3', 'A3', 'A3', 'A3', 'A3', 'A3', 'A3'],\n",
    "    'Terrain': ['Flat', 'Flat', 'Flat', 'Hilly', 'Hilly', 'Hilly', 'Mountainous', 'Mountainous', 'Mountainous',\n",
    "                'Flat', 'Flat', 'Flat', 'Hilly', 'Hilly', 'Hilly', 'Mountainous', 'Mountainous', 'Mountainous',\n",
    "                'Flat', 'Flat', 'Flat', 'Hilly', 'Hilly', 'Hilly', 'Mountainous', 'Mountainous', 'Mountainous'],\n",
    "    'Weather': ['S1', 'S2', 'S3', 'S1', 'S2', 'S3', 'S1', 'S2', 'S3',\n",
    "                'S1', 'S2', 'S3', 'S1', 'S2', 'S3', 'S1', 'S2', 'S3',\n",
    "                'S1', 'S2', 'S3', 'S1', 'S2', 'S3', 'S1', 'S2', 'S3'],\n",
    "    'Cost (CHF)': [500, 510, 520, 450, 460, 470, 550, 560, 570,\n",
    "                   450, 460, 470, 400, 410, 420, 500, 510, 520,\n",
    "                   550, 560, 570, 500, 510, 520, 600, 610, 620],\n",
    "    'Design (# friends approve)': [10, 11, 12, 10, 11, 12, 10, 11, 12,\n",
    "                                   9, 8, 7, 9, 8, 7, 9, 8, 7,\n",
    "                                   13, 14, 15, 13, 14, 15, 13, 14, 15],\n",
    "    'Max Speed (km/h)': [25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "                         25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "                         25, 26, 27, 28, 29, 30, 31, 32, 33],\n",
    "    'Comfort (Minutes until pain)': [30, 35, 40, 45, 50, 55, 60, 65, 70,\n",
    "                                     30, 35, 40, 45, 50, 55, 60, 65, 70,\n",
    "                                     30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'Durability (Years)': [5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
    "                           5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
    "                           5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "dm_df = pd.DataFrame(data)\n",
    "\n",
    "# Define additional parameters\n",
    "objectives = {\n",
    "    \"Cost (CHF)\": -1,\n",
    "    \"Design (# friends approve)\": 1,\n",
    "    \"Max Speed (km/h)\": 1,\n",
    "    \"Comfort (Minutes until pain)\": 1,\n",
    "    \"Durability (Years)\": 1\n",
    "}\n",
    "\n",
    "weights = {\n",
    "    \"Cost (CHF)\": 0.30,\n",
    "    \"Design (# friends approve)\": 0.20,\n",
    "    \"Max Speed (km/h)\": 0.20,\n",
    "    \"Comfort (Minutes until pain)\": 0.10,\n",
    "    \"Durability (Years)\": 0.20\n",
    "}\n",
    "\n",
    "group_cols = [\"Terrain\"]\n",
    "group_weights = {\n",
    "    \"Terrain\": {\n",
    "        \"Flat\": 0.5,\n",
    "        \"Hilly\": 0.3,\n",
    "        \"Mountainous\": 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "alt_cols = [\"Alternative\"]\n",
    "crit_cols = [\"Cost (CHF)\", \"Design (# friends approve)\", \"Max Speed (km/h)\", \"Comfort (Minutes until pain)\", \"Durability (Years)\"]\n",
    "unc_cols = [\"Weather\"]\n",
    "\n",
    "# Create the DecisionMatrix instance\n",
    "dm = DecisionMatrix(\n",
    "    metrics_df=dm_df,\n",
    "    objectives=objectives,\n",
    "    alt_cols=alt_cols,\n",
    "    crit_cols=crit_cols,\n",
    "    weights=weights,\n",
    "    group_cols=group_cols,\n",
    "    group_weights=group_weights,\n",
    "    unc_cols=unc_cols\n",
    ")\n",
    "\n",
    "# Print the DataFrame to ensure it's correctly set up\n",
    "print(dm.dm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups – Bike performance at differnt Places Example City, Rural, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNcertainy - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DecisionMatrix import DecisionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "class DecisionMatrix:\n",
    "    def __init__(\n",
    "        self,\n",
    "        metrics_df: pd.DataFrame,\n",
    "        objectives: Dict[str, int],\n",
    "        alt_cols: List[str],\n",
    "        crit_cols: List[str],\n",
    "        weights: Optional[Dict[str, float]] = None,\n",
    "        group_cols: Optional[List[str]] = [],\n",
    "        group_weights: Optional[Dict[str, float]] = None,\n",
    "        unc_cols: Optional[List[str]] = [],\n",
    "        crit_cats: Optional[Dict[str, List[str]]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the DecisionMatrix object.\n",
    "\n",
    "        Parameters:\n",
    "        - metrics_df : pd.DataFrame\n",
    "            DataFrame containing metrics data.\n",
    "        - objectives : Dict[str, int]\n",
    "            Dictionary mapping objectives to their values.\n",
    "        - alt_cols : List[str]\n",
    "            List of alternative columns.\n",
    "        - crit_cols : List[str]\n",
    "            List of criteria columns.\n",
    "        - weights : Dict[str, float], optional\n",
    "            Dictionary of criteria weights values. Defaults to an empty dictionary.\n",
    "        - group_cols : List[str], optional\n",
    "            List of group columns. Defaults to an empty list.\n",
    "        - group_weights : Dict[str, float], optional\n",
    "            Dictionary of weights for group columns. Defaults to an empty dictionary.\n",
    "        - unc_cols : List[str], optional\n",
    "            List of uncertainty columns. Defaults to an empty list.\n",
    "        - crit_cats : Dict[str, List[str]], optional\n",
    "            Dictionary of categorized criteria. Defaults to an empty dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Assign input parameters to class attributes as copies\n",
    "        self.metrics_df = metrics_df.copy()\n",
    "        self.objectives = copy.deepcopy(objectives)\n",
    "        self.alt_cols = alt_cols.copy()\n",
    "        self.crit_cols = crit_cols.copy()\n",
    "        self.weights = weights.copy() if weights is not None else {}\n",
    "        self.group_cols = group_cols.copy() if group_cols is not None else []\n",
    "        self.group_weights = group_weights.copy() if group_weights is not None else {}\n",
    "        self.unc_cols = unc_cols.copy() if unc_cols is not None else []\n",
    "        self.crit_cats = crit_cats.copy() if crit_cats is not None else {}\n",
    "\n",
    "        # Initialize dataframes – Attributes to store dataframes used for calculations and organization\n",
    "        self._initialize_dataframes()\n",
    "\n",
    "        # Process initial data\n",
    "        self._process_initial_data()\n",
    "\n",
    "\n",
    "    # Method to initialize dataframes\n",
    "    def _initialize_dataframes(self):\n",
    "        self.dm_df = None # Decision matrix dataframe ( The main dataframe)\n",
    "        self.alternatives_df = None # Alternatives dataframe (unique alternatives, their IDs\n",
    "        self.crit_df = None # Criteria dataframe (criteria and their weights)\n",
    "        self.cat_crit_df = None # Categorized criteria dataframe (criteria and their categories)\n",
    "        self.groups_df = None # Groups dataframe (if group columns are provided, otherwise None)\n",
    "        self.unc_smpls_df = None # Uncertainty samples dataframe (if uncertainty columns are provided, otherwise None)\n",
    "\n",
    "    # Method to process initial data\n",
    "    def _process_initial_data(self):\n",
    "        self._sort_metrics_df()                # Sort metrics_df by alternative, group, and uncertainty columns for readability in the decision matrix\n",
    "        self._validate_inputs()                # Validate inputs for duplicate rows based on alternative, group, and uncertainty columns\n",
    "        self._calculate_weights()              # Calculate weights for criteria and group columns if not provided\n",
    "        self._prepare_criteria_dataframes()    # Prepare criteria dataframes (criteria and categorized criteria)\n",
    "        self._prepare_alternatives_dataframe() # Prepare alternatives dataframe (unique alternatives)\n",
    "        self._prepare_decision_matrix_dataframe() # Prepare decision matrix dataframe by merging alternatives, groups, and uncertainty samples\n",
    "\n",
    "    # Method to sort metrics dataframe\n",
    "    def _sort_metrics_df(self):\n",
    "        \"\"\"\n",
    "        Sort the metrics DataFrame by alternative, group, and uncertainty columns.\n",
    "        Sorting by alternative, group, and uncertainty columns makes the decision matrix more readable.\n",
    "        \"\"\"\n",
    "        self.metrics_df = self.metrics_df.sort_values(by=self.alt_cols + self.group_cols + self.unc_cols)\n",
    "\n",
    "    # Method to validate inputs\n",
    "    def _validate_inputs(self):\n",
    "        \"\"\"\n",
    "        Validate the input DataFrame for duplicate rows based on alternative, group, and uncertainty columns.\n",
    "        Each alternative could only have one unique combination of group and uncertainty columns.\n",
    "        \"\"\"\n",
    "        if self.metrics_df.duplicated(subset=self.alt_cols + self.group_cols + self.unc_cols, keep=False).any():\n",
    "            raise ValueError(\"Duplicated rows of alt_cols, group_cols, and sample. Some alternative IDs are counted more than once for some group ID and sample ID pairs.\")\n",
    "\n",
    "    # Method to calculate weights\n",
    "    def _calculate_weights(self):\n",
    "        \"\"\"\n",
    "        Calculate weights for criteria and group columns if not provided.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Assign equal weights to criteria if not provided.\n",
    "        2. Calculate and assign weights to group members if group columns are specified.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if weights for criteria are provided\n",
    "        if not self.weights:\n",
    "            # Define a custom rounding function to handle precision\n",
    "            def custom_round(value):\n",
    "                # Determine the number of decimal places\n",
    "                decimal_count = len(str(value).split(\".\")[1]) if \".\" in str(value) else 0\n",
    "                # Round to a maximum of two decimal places\n",
    "                decimals = 2 if decimal_count >= 2 else 1\n",
    "                return round(value, decimals)\n",
    "            \n",
    "            # Assign equal weights to each criterion\n",
    "            self.weights = {crit: custom_round(1/len(self.crit_cols)) for crit in self.crit_cols}\n",
    "\n",
    "        # Check if there are group columns specified\n",
    "        if self.group_cols:\n",
    "            # Drop duplicates to identify unique groups and reset the index\n",
    "            self.groups_df = self.metrics_df[self.group_cols].drop_duplicates().reset_index(drop=True)\n",
    "            # Assign a unique 'Group ID' to each group\n",
    "            self.groups_df.insert(0, 'Group ID', ['G' + str(idx) for idx in range(1, len(self.groups_df) + 1)])\n",
    "            \n",
    "            # Iterate through each group column\n",
    "            for group_col in self.group_cols:\n",
    "                # Create a temporary DataFrame with unique values of the group column\n",
    "                temp_df = pd.DataFrame(self.metrics_df[group_col].drop_duplicates())\n",
    "                # Initialize a 'Weight' column with NaN values\n",
    "                temp_df['Weight'] = np.nan\n",
    "                \n",
    "                # Iterate through each member of the group\n",
    "                for idx, member in temp_df.iterrows():\n",
    "                    member_name = member[group_col]\n",
    "                    # Assign provided group weight if available\n",
    "                    if member_name != 'ALL' and self.group_weights and group_col in self.group_weights and isinstance(self.group_weights[group_col], dict) and member_name in self.group_weights[group_col]:\n",
    "                        temp_df.at[idx, 'Weight'] = self.group_weights[group_col][member_name]\n",
    "                \n",
    "                # Exclude rows where the group column value is 'ALL'\n",
    "                temp_df = temp_df[temp_df[group_col] != 'ALL']\n",
    "                # Calculate the sum of defined weights\n",
    "                sum_defined_weights = temp_df['Weight'].sum()\n",
    "                # Identify members with undefined weights\n",
    "                remaining_members = temp_df[temp_df['Weight'].isna()]\n",
    "                remaining_count = len(remaining_members)\n",
    "                \n",
    "                # Distribute the remaining weight equally among members with undefined weights\n",
    "                if remaining_count > 0:\n",
    "                    remainder = 1 - sum_defined_weights\n",
    "                    equal_weight = remainder / remaining_count\n",
    "                    temp_df.loc[temp_df['Weight'].isna(), 'Weight'] = equal_weight\n",
    "                \n",
    "                # Update the group weights with the calculated weights\n",
    "                self.group_weights[group_col] = temp_df\n",
    "\n",
    "\n",
    "    # Method to prepare criteria dataframes\n",
    "    def _prepare_criteria_dataframes(self):\n",
    "        \"\"\"\n",
    "        Prepare DataFrames for criteria and categorized criteria.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Create a DataFrame for criteria with their IDs, weights, and objectives.\n",
    "        2. Create a dictionary for categorized criteria if not provided.\n",
    "        3. Create a DataFrame for categorized criteria and merge it with the criteria DataFrame.\n",
    "\n",
    "        Steps:\n",
    "        1. Create a DataFrame for criteria:\n",
    "            - Generate criteria IDs.\n",
    "            - Assign criteria weights and objectives.\n",
    "        2. Check if categorized criteria are provided:\n",
    "            - If not, create a default categorization where each criterion is its own category.\n",
    "        3. Create a DataFrame for categorized criteria:\n",
    "            - Assign category IDs.\n",
    "            - Merge categorized criteria with the main criteria DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Create a DataFrame for criteria\n",
    "        self.crit_df = pd.DataFrame([\n",
    "            {'Criteria ID': 'C' + str(idx + 1), 'Criteria': crit, 'Weight': self.weights[crit], 'Objective': self.objectives[crit]}\n",
    "            for idx, crit in enumerate(self.crit_cols)\n",
    "        ])\n",
    "\n",
    "        # Step 2: Check if categorized criteria are provided\n",
    "        if not self.crit_cats:\n",
    "            # Create a default categorization where each criterion is its own category\n",
    "            self.crit_cats = {crit: [crit] for crit in self.crit_cols}\n",
    "\n",
    "        # Step 3: Create a DataFrame for categorized criteria\n",
    "        data = [\n",
    "            {'Cat ID': 'CAT' + str(idx + 1), 'Category': cat, 'Criteria': crit}\n",
    "            for idx, (cat, crits) in enumerate(self.crit_cats.items())\n",
    "            for crit in crits\n",
    "        ]\n",
    "        self.cat_crit_df = pd.DataFrame(data).merge(self.crit_df, on='Criteria')\n",
    "\n",
    "    # Method to prepare alternatives dataframe\n",
    "    def _prepare_alternatives_dataframe(self):\n",
    "        \"\"\"\n",
    "        Prepare the alternatives DataFrame.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Check if alternative columns are provided.\n",
    "        2. Create a DataFrame for unique alternatives.\n",
    "        3. Assign unique IDs to each alternative.\n",
    "\n",
    "        Steps:\n",
    "        1. Check for alternative columns:\n",
    "            - Raise an error if not provided.\n",
    "        2. Create a DataFrame for unique alternatives:\n",
    "            - Drop duplicate rows.\n",
    "        3. Assign unique IDs to each alternative:\n",
    "            - Insert an 'Alternative ID' column with unique IDs.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Check for alternative columns\n",
    "        if not self.alt_cols:\n",
    "            raise ValueError(\"No alternative column given.\")\n",
    "\n",
    "        # Step 2: Create a DataFrame for unique alternatives\n",
    "        self.alternatives_df = self.metrics_df[self.alt_cols].drop_duplicates()\n",
    "\n",
    "        # Step 3: Assign unique IDs to each alternative\n",
    "        self.alternatives_df.insert(0, 'Alternative ID', ['A' + str(idx) for idx in range(1, len(self.alternatives_df) + 1)])\n",
    "\n",
    "    # Method to prepare decision matrix dataframe\n",
    "    def _prepare_decision_matrix_dataframe(self):\n",
    "        \"\"\"\n",
    "        Prepare the decision matrix DataFrame by merging alternatives, groups, and uncertainty samples.\n",
    "\n",
    "        This method performs the following main tasks:\n",
    "        1. Initialize the decision matrix with the alternatives DataFrame.\n",
    "        2. Merge the decision matrix with groups DataFrame if available.\n",
    "        3. Merge the decision matrix with uncertainty samples DataFrame if available.\n",
    "        4. Merge the decision matrix with the metrics DataFrame on specified columns.\n",
    "\n",
    "        Steps:\n",
    "        1. Initialize the decision matrix:\n",
    "            - Copy the alternatives DataFrame.\n",
    "        2. Merge with groups DataFrame:\n",
    "            - If available, merge on a temporary '_merge' column.\n",
    "        3. Merge with uncertainty samples DataFrame:\n",
    "            - If available, merge on a temporary '_merge' column.\n",
    "        4. Finalize the decision matrix:\n",
    "            - Drop the temporary '_merge' column.\n",
    "            - Merge with the metrics DataFrame on alternative, group, and uncertainty columns.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Initialize the decision matrix\n",
    "        self.dm_df = self.alternatives_df.copy()\n",
    "        self.dm_df['_merge'] = 1\n",
    "\n",
    "        # Step 2: Merge with groups DataFrame if available\n",
    "        if isinstance(self.groups_df, pd.DataFrame):\n",
    "            self.groups_df['_merge'] = 1\n",
    "            self.dm_df = self.dm_df.merge(self.groups_df, on='_merge')\n",
    "            self.groups_df = self.groups_df.drop('_merge', axis=1)\n",
    "\n",
    "        # Step 3: Merge with uncertainty samples DataFrame if available\n",
    "        if isinstance(self.unc_smpls_df, pd.DataFrame):\n",
    "            self.unc_smpls_df['_merge'] = 1\n",
    "            self.dm_df = self.dm_df.merge(self.unc_smpls_df, on='_merge')\n",
    "            self.unc_smpls_df = self.unc_smpls_df.drop('_merge', axis=1)\n",
    "\n",
    "        # Step 4: Finalize the decision matrix\n",
    "        self.dm_df = self.dm_df.drop('_merge', axis=1)\n",
    "        self.dm_df = pd.merge(self.dm_df, self.metrics_df[self.alt_cols + self.group_cols + self.unc_cols + self.crit_cols], on=self.alt_cols + self.group_cols + self.unc_cols, how='left')\n",
    "\n",
    "\n",
    "\n",
    "    # Method to plot criteria (used in plot_criteria)\n",
    "    def plot_criteria(self, group_by_category=True):\n",
    "        \"\"\"\n",
    "        Plots the weights of criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - group_by_category (bool): If True, the criteria will be grouped by category and displayed as a stacked bar plot. \n",
    "                    If False, the criteria will be displayed as individual bars.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Get the criteria and colors\n",
    "        criteria_colors = self._generate_criteria_colors()\n",
    "\n",
    "        if group_by_category:\n",
    "            self._plot_grouped_criteria(criteria_colors)\n",
    "        else:\n",
    "            self._plot_individual_criteria(criteria_colors)\n",
    "\n",
    "    # Method to generate criteria colors (used in plot_criteria)\n",
    "    def _generate_criteria_colors(self):\n",
    "        \"\"\"\n",
    "        Generate a dictionary mapping each criterion to a unique color.\n",
    "\n",
    "        Returns:\n",
    "        - criteria_colors: Dict[str, str]\n",
    "            A dictionary mapping criteria to colors.\n",
    "        \"\"\"\n",
    "        # Get a list of unique criteria\n",
    "        criteria = self.crit_df['Criteria'].unique()\n",
    "\n",
    "        # Generate a list of unique colors\n",
    "        colors = list(mcolors.CSS4_COLORS.keys())\n",
    "        colors.remove('black')  # Remove 'black' from the list of colors\n",
    "        colors = colors[:len(criteria)]\n",
    "\n",
    "        # Make colors for each criterion and store in dictionary\n",
    "        criteria_colors = dict(zip(criteria, colors))\n",
    "\n",
    "        return criteria_colors\n",
    "\n",
    "    # Method to plot grouped criteria (used in plot_criteria)\n",
    "    def _plot_grouped_criteria(self, criteria_colors):\n",
    "        \"\"\"\n",
    "        Plot the criteria grouped by category.\n",
    "\n",
    "        Parameters:\n",
    "        - criteria_colors: Dict[str, str]\n",
    "            A dictionary mapping criteria to colors.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Create a bar plot from the pivoted DataFrame with stacked bars\n",
    "        df = self.cat_crit_df.pivot(index='Category', columns='Criteria', values='Weight')\n",
    "        ax = df.plot(kind='bar', stacked=True, figsize=(15, 8), color=[criteria_colors[crit] for crit in df.columns])\n",
    "        \n",
    "        # Annotate the bars with the weights\n",
    "        cumulative_height = np.zeros(len(df))\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            bar_index = i % len(df)\n",
    "            cumulative_height[bar_index] += p.get_height()\n",
    "            if p.get_height() > 0:\n",
    "                ax.annotate(str(round(p.get_height(), 2)), (p.get_x() + p.get_width() / 2., cumulative_height[bar_index] - p.get_height() / 2), ha='center', va='center')\n",
    "\n",
    "        # Customize the plot\n",
    "        ax.set_xlabel('Criteria categories', fontsize=12)\n",
    "        ax.set_xticklabels([label[:10] for label in df.index], rotation=45)\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=4, mode=\"expand\", borderaxespad=0., edgecolor='black', title='Criteria', fontsize=12)\n",
    "        ax.set_ylabel('Weight', fontsize=12)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid(True, linestyle=':')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Method to plot individual criteria (used in plot_criteria)\n",
    "    def _plot_individual_criteria(self, criteria_colors):\n",
    "        \"\"\"\n",
    "        Plot individual criteria without grouping by category.\n",
    "\n",
    "        Parameters:\n",
    "        - criteria_colors: Dict[str, str]\n",
    "            A dictionary mapping criteria to colors.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Create a bar plot with individual criteria\n",
    "        ax = self.crit_df.plot(x='Criteria', y='Weight', kind='bar', figsize=(15, 8), color=[criteria_colors[crit] for crit in self.crit_df['Criteria']], title='Weight of criteria', legend=False)\n",
    "        \n",
    "        # Annotate the bars with the weights\n",
    "        for p in ax.patches:\n",
    "            if p.get_height() > 0:\n",
    "                ax.annotate(str(round(p.get_height(), 2)), (p.get_x() + p.get_width() / 2., p.get_height() / 2), ha='center', va='center')\n",
    "\n",
    "        # Customize the plot\n",
    "        ax.set_xlabel('Criteria', fontsize=12)\n",
    "        ax.set_xticklabels([label[:10] for label in self.crit_df['Criteria']], rotation=45)\n",
    "        ax.set_ylabel('Weight', fontsize=12)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid(True, linestyle=':')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Method to filter and define columns (used in mean_based_criteria)\n",
    "    def mean_based_criteria(self, condition={}, derived_columns=None):\n",
    "        \"\"\"\n",
    "        Apply mean-based criteria to the decision matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - condition: dict, optional\n",
    "            Conditions to filter the data.\n",
    "        - derived_columns: list, optional\n",
    "            List of derived columns.\n",
    "\n",
    "        Returns:\n",
    "        - new_self: DecisionMatrix\n",
    "            A new instance of DecisionMatrix with mean-based criteria.\n",
    "        \"\"\"\n",
    "        dm_df = self.dm_df.copy()\n",
    "        # Define base columns for the mean-based criteria\n",
    "        base_cols = self._define_base_columns(dm_df)\n",
    "        # Apply mean-based criteria to the DataFrame\n",
    "        new_dm_df = self._apply_mean_based_criteria(dm_df, base_cols, condition, derived_columns)\n",
    "        # Remove the group column if only one group is present\n",
    "        new_dm_df = self._remove_single_group_column(new_dm_df)\n",
    "\n",
    "        return self._create_new_instance(new_dm_df)\n",
    "\n",
    "    # Method to define base columns (used in mean_based_criteria)\n",
    "    def _define_base_columns(self, dm_df):\n",
    "        \"\"\"\n",
    "        Define base columns for the mean-based criteria.\n",
    "\n",
    "        Parameters:\n",
    "        - dm_df: pd.DataFrame\n",
    "            The decision matrix DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - base_cols: list\n",
    "            List of base columns.\n",
    "        \"\"\"\n",
    "        # Define base columns for the mean-based criteria\n",
    "        base_cols = list(self.alternatives_df.columns) + ['Group ID']\n",
    "        if isinstance(self.groups_df, pd.DataFrame):\n",
    "            base_cols += list(self.groups_df.columns)\n",
    "        else:\n",
    "            dm_df['Group ID'] = 'G1'\n",
    "        base_cols = list(dict.fromkeys(base_cols))\n",
    "        return base_cols\n",
    "\n",
    "    # Method to apply mean-based criteria (used in mean_based_criteria)\n",
    "    def _apply_mean_based_criteria(self, dm_df, base_cols, condition, derived_columns):\n",
    "        \"\"\"\n",
    "        Apply mean-based criteria to the DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        - dm_df: pd.DataFrame\n",
    "            The decision matrix DataFrame.\n",
    "        - base_cols: list\n",
    "            List of base columns.\n",
    "        - condition: dict, optional\n",
    "            Conditions to filter the data.\n",
    "        - derived_columns: list, optional\n",
    "            List of derived columns.\n",
    "\n",
    "        Returns:\n",
    "        - new_dm_df: pd.DataFrame\n",
    "            The new decision matrix DataFrame with mean-based criteria.\n",
    "        \"\"\"\n",
    "        new_dm_df = pd.DataFrame(columns=base_cols + self.crit_cols)\n",
    "\n",
    "        for _, alt_group_df in dm_df[['Alternative ID', 'Group ID']].drop_duplicates().iterrows():\n",
    "            sg_df = dm_df[dm_df[['Alternative ID', 'Group ID']].isin(alt_group_df[['Alternative ID', 'Group ID']].values).all(axis=1)]\n",
    "            filt_sg_df, _ = filter_dataframe(sg_df, filter_conditions=condition, derived_columns=derived_columns)\n",
    "\n",
    "            if filt_sg_df.empty:\n",
    "                print(f\"The alternative {alt_group_df['Alternative ID']} in group {alt_group_df['Group ID']} did not satisfy the condition and is filtered out.\")\n",
    "                continue\n",
    "\n",
    "            mean_crits_temp_df = filt_sg_df[self.crit_cols].mean()\n",
    "            base_temp_df = sg_df[base_cols].drop_duplicates().assign(**mean_crits_temp_df)\n",
    "\n",
    "            new_dm_df = pd.concat([new_dm_df, base_temp_df], ignore_index=True) if not new_dm_df.empty else base_temp_df\n",
    "\n",
    "        return new_dm_df\n",
    "\n",
    "    # Method to filter dataframe (used in mean_based_criteria)\n",
    "    def _remove_single_group_column(self, new_dm_df):\n",
    "        \"\"\"\n",
    "        Remove the group column if only one group is present.\n",
    "\n",
    "        Parameters:\n",
    "        - new_dm_df: pd.DataFrame\n",
    "            The new decision matrix DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - new_dm_df: pd.DataFrame\n",
    "            The updated decision matrix DataFrame.\n",
    "        \"\"\"\n",
    "        if len(new_dm_df['Group ID'].unique()) == 1:\n",
    "            new_dm_df = new_dm_df.drop(columns=['Group ID'])\n",
    "        return new_dm_df\n",
    "\n",
    "    # Method to create new instance (used in mean_based_criteria)\n",
    "    def _create_new_instance(self, new_dm_df):\n",
    "        \"\"\"\n",
    "        Create a new DecisionMatrix instance with the updated DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        - new_dm_df: pd.DataFrame\n",
    "            The new decision matrix DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - new_self: DecisionMatrix\n",
    "            A new instance of DecisionMatrix with updated attributes.\n",
    "        \"\"\"\n",
    "        return DecisionMatrix(\n",
    "            metrics_df=new_dm_df,\n",
    "            objectives=self.objectives,\n",
    "            alt_cols=self.alt_cols,\n",
    "            crit_cols=self.crit_cols,\n",
    "            weights=self.weights,\n",
    "            group_cols=self.group_cols,\n",
    "            crit_cats=self.crit_cats,\n",
    "            group_weights=self.group_weights,\n",
    "        )\n",
    "\n",
    "    def pivot_and_reweight_criteria(self, piv_col):\n",
    "        \"\"\"\n",
    "        Pivot and reweight criteria based on a specified pivot column and group weights.\n",
    "\n",
    "        Parameters:\n",
    "        - piv_col: str\n",
    "            The column name to pivot the criteria data.\n",
    "\n",
    "        Returns:\n",
    "        - new_self: DecisionMatrix\n",
    "            A new instance of DecisionMatrix with pivoted criteria.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define pivot and index columns for pivot\n",
    "        index_col = [col for col in self.alt_cols + self.unc_cols + self.group_cols if col not in self.crit_cols + [piv_col]]\n",
    "\n",
    "        # Filter out rows where the specified column is ALL or nan\n",
    "        filt_dm_df = self.dm_df[self.alt_cols + self.unc_cols + self.group_cols + self.crit_cols]\n",
    "        filt_dm_df = filt_dm_df[~filt_dm_df[piv_col].isin(['ALL']) & filt_dm_df[piv_col].notna()]\n",
    "\n",
    "        # Pivot the criteria dataframe\n",
    "        crit_piv_df = filt_dm_df.pivot(index=index_col, columns=piv_col, values=self.crit_cols)\n",
    "\n",
    "        # Reset index to flatten the DataFrame\n",
    "        crit_piv_df = crit_piv_df.reset_index()\n",
    "        crit_piv_df.columns = [f'{col[0]}_{col[1]}' if col[1] else f'{col[0]}' for col in crit_piv_df.columns]\n",
    "\n",
    "        # Remove duplicates and create a copy of weights and objectives\n",
    "        new_weights = copy.deepcopy(self.weights)\n",
    "        new_crit_cats = {key: [] for key in self.crit_cats.keys()}\n",
    "        group_values = list(filt_dm_df[piv_col].dropna().drop_duplicates())\n",
    "        new_objectives = copy.deepcopy(self.objectives)\n",
    "\n",
    "        for crit_col in self.crit_cols:\n",
    "            new_crit_cols_temp = [crit_col + '_' + group_value for group_value in group_values]\n",
    "            temp_df = crit_piv_df[new_crit_cols_temp]\n",
    "\n",
    "            cat_crit = self.cat_crit_df[self.cat_crit_df['Criteria'].isin([crit_col])]['Category'].values[0]\n",
    "\n",
    "            # Check if all columns have the same values\n",
    "            if temp_df.apply(lambda col: col.equals(temp_df.iloc[:, 0])).all():\n",
    "                crit_piv_df = crit_piv_df.rename(columns={new_crit_cols_temp[0]: crit_col})\n",
    "                if len(new_crit_cols_temp) > 1:\n",
    "                    crit_piv_df = crit_piv_df.drop(columns=new_crit_cols_temp[1:])\n",
    "                new_crit_cats[cat_crit].append(crit_col)\n",
    "            else:\n",
    "                for group_value in group_values:\n",
    "                    idx = self.group_weights[piv_col][piv_col].isin([group_value])\n",
    "                    group_weight = self.group_weights[piv_col]['Weight'][idx].values[0]\n",
    "                    new_weights.update({crit_col + '_' + group_value: new_weights[crit_col] * group_weight})\n",
    "                    new_objectives[crit_col + '_' + group_value] = self.objectives[crit_col]\n",
    "                    new_crit_cats[cat_crit].append(crit_col + '_' + group_value)\n",
    "                del new_weights[crit_col]\n",
    "                del new_objectives[crit_col]\n",
    "\n",
    "        # Include consistent criteria back to the pivoted dataframe\n",
    "        for crit_col in self.crit_cols:\n",
    "            if crit_col not in new_weights:\n",
    "                crit_piv_df[crit_col] = self.dm_df[crit_col].unique()[0]\n",
    "\n",
    "        new_crit_cols = list(new_objectives.keys())\n",
    "        new_group_cols = [col for col in self.group_cols if col != piv_col]\n",
    "        new_group_weights = {key: value for key, value in self.group_weights.items() if key != piv_col}\n",
    "\n",
    "        # Create and return a new DecisionMatrix instance with modified attributes\n",
    "        return DecisionMatrix(\n",
    "            metrics_df=crit_piv_df,\n",
    "            objectives=new_objectives,\n",
    "            alt_cols=self.alt_cols,\n",
    "            crit_cols=new_crit_cols,\n",
    "            weights=new_weights,\n",
    "            group_cols=new_group_cols,\n",
    "            unc_cols=self.unc_cols,\n",
    "            crit_cats=new_crit_cats,\n",
    "            group_weights=new_group_weights\n",
    "        )\n",
    "\n",
    "\n",
    "    def mean_based_criteria(self, condition={}, derived_columns=None):\n",
    "        \"\"\"\n",
    "        Create a new decision matrix by calculating the mean criteria values based on specified conditions and groups.\n",
    "\n",
    "        Parameters:\n",
    "        - condition (dict): A dictionary specifying conditions to filter the decision matrix. Defaults to an empty dictionary.\n",
    "        - derived_columns (list, optional): A list of derived columns to consider during filtering. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        - DecisionMatrix: A new instance of DecisionMatrix with criteria values averaged based on the specified conditions and groups.\n",
    "\n",
    "        Process:\n",
    "        1. Copy the original decision matrix to ensure the original data remains unchanged.\n",
    "        2. Define the base columns, including alternative columns and a group identifier ('Group ID').\n",
    "        3. Initialize an empty DataFrame to store the results.\n",
    "        4. Iterate through each unique combination of 'Alternative ID' and 'Group ID'.\n",
    "        - Filter the decision matrix based on the specified conditions.\n",
    "        - Calculate the mean values for the criteria columns for each filtered group.\n",
    "        - Add the mean criteria values to the new DataFrame.\n",
    "        5. Ensure that the 'Group ID' column is only included if there is more than one group.\n",
    "        6. Create and return a new DecisionMatrix instance with the modified attributes.\n",
    "        \"\"\"\n",
    "        dm_df = self.dm_df.copy()  # Create a copy of the decision matrix\n",
    "\n",
    "        # Define base columns including 'Group ID'\n",
    "        base_cols = list(self.alternatives_df.columns) + ['Group ID']\n",
    "        if isinstance(self.groups_df, pd.DataFrame):\n",
    "            base_cols += list(self.groups_df.columns)\n",
    "        else:\n",
    "            dm_df['Group ID'] = 'G1'  # Assign 'G1' if there are no groups\n",
    "\n",
    "        base_cols = list(dict.fromkeys(base_cols))  # Remove duplicates in base_cols\n",
    "\n",
    "        # Initialize an empty DataFrame to store results\n",
    "        new_dm_df = pd.DataFrame(columns=base_cols + self.crit_cols)\n",
    "\n",
    "        # Iterate through unique combinations of 'Alternative ID' and 'Group ID'\n",
    "        for _, alt_group_df in dm_df[['Alternative ID', 'Group ID']].drop_duplicates().iterrows():\n",
    "            sg_df = dm_df[dm_df[['Alternative ID', 'Group ID']].isin(alt_group_df[['Alternative ID', 'Group ID']].values).all(axis=1)]\n",
    "            \n",
    "            # Filter the dataframe based on the condition \n",
    "            filt_sg_df, _ = filter_dataframe(sg_df, filter_conditions=condition, derived_columns=derived_columns)\n",
    "\n",
    "            # If the filtered dataframe is empty, continue to the next iteration\n",
    "            if filt_sg_df.empty:\n",
    "                print(f\"The alternative {alt_group_df['Alternative ID']} in group {alt_group_df['Group ID']} did not satisfy the condition and is filtered out.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate the mean of the criteria\n",
    "            mean_crits_temp_df = filt_sg_df[self.crit_cols].mean()\n",
    "\n",
    "            # Add the mean criteria values to the base dataframe\n",
    "            base_temp_df = sg_df[base_cols].drop_duplicates()\n",
    "            base_temp_df = base_temp_df.assign(**mean_crits_temp_df)\n",
    "\n",
    "            # Add the results to the new DataFrame\n",
    "            if new_dm_df.empty:\n",
    "                new_dm_df = base_temp_df\n",
    "            else:\n",
    "                new_dm_df = pd.concat([new_dm_df, base_temp_df], ignore_index=True)\n",
    "\n",
    "        # If only one group is present, remove the 'Group ID' column\n",
    "        if len(new_dm_df['Group ID'].unique()) == 1:\n",
    "            new_dm_df = new_dm_df.drop(columns=['Group ID'])\n",
    "\n",
    "        # Create a new DecisionMatrix instance with modified attributes\n",
    "        new_self = DecisionMatrix(\n",
    "            metrics_df=new_dm_df,\n",
    "            objectives=self.objectives,\n",
    "            alt_cols=self.alt_cols,\n",
    "            crit_cols=self.crit_cols,\n",
    "            weights=self.weights,\n",
    "            group_cols=self.group_cols,\n",
    "            crit_cats=self.crit_cats,\n",
    "            group_weights=self.group_weights,\n",
    "        )\n",
    "        \n",
    "        return new_self\n",
    "    \n",
    "    def mean_based_criteria(self, condition={}, derived_columns=None):\n",
    "        \"\"\"\n",
    "        Calculate the mean criteria values for each group and alternative.\n",
    "\n",
    "        Parameters:\n",
    "        - condition: dict, optional\n",
    "            Conditions to filter the data.\n",
    "        - derived_columns: list, optional\n",
    "            List of derived columns.\n",
    "\n",
    "        Returns:\n",
    "        - DecisionMatrix: A new instance of DecisionMatrix with mean-based criteria.\n",
    "        \"\"\"\n",
    "        dm_df = self.dm_df.copy()\n",
    "\n",
    "        # Define base columns including 'Group ID'\n",
    "        base_cols = list(self.alternatives_df.columns) + ['Group ID']\n",
    "        if isinstance(self.groups_df, pd.DataFrame):\n",
    "            base_cols += list(self.groups_df.columns)\n",
    "        else:\n",
    "            dm_df['Group ID'] = 'G1'  # Assign 'G1' if there are no groups\n",
    "\n",
    "        base_cols = list(dict.fromkeys(base_cols))  # Remove duplicates in base_cols\n",
    "\n",
    "        # Initialize an empty DataFrame to store results\n",
    "        new_dm_df = pd.DataFrame(columns=base_cols + self.crit_cols)\n",
    "\n",
    "        # Iterate through unique combinations of 'Alternative ID' and 'Group ID'\n",
    "        for _, alt_group_df in dm_df[['Alternative ID', 'Group ID']].drop_duplicates().iterrows():\n",
    "            sg_df = dm_df[dm_df[['Alternative ID', 'Group ID']].isin(alt_group_df[['Alternative ID', 'Group ID']].values).all(axis=1)]\n",
    "            \n",
    "            # Filter the dataframe based on the condition \n",
    "            filt_sg_df, _ = filter_dataframe(sg_df, filter_conditions=condition, derived_columns=derived_columns)\n",
    "\n",
    "            # If the filtered dataframe is empty, continue to the next iteration\n",
    "            if filt_sg_df.empty:\n",
    "                print(f\"The alternative {alt_group_df['Alternative ID']} in group {alt_group_df['Group ID']} did not satisfy the condition and is filtered out.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate the mean of the criteria\n",
    "            mean_crits_temp_df = filt_sg_df[self.crit_cols].mean()\n",
    "\n",
    "            # Add the mean criteria values to the base dataframe\n",
    "            base_temp_df = sg_df[base_cols].drop_duplicates()\n",
    "            base_temp_df = base_temp_df.assign(**mean_crits_temp_df)\n",
    "\n",
    "            # Add the results to the new DataFrame\n",
    "            if new_dm_df.empty:\n",
    "                new_dm_df = base_temp_df\n",
    "            else:\n",
    "                new_dm_df = pd.concat([new_dm_df, base_temp_df], ignore_index=True)\n",
    "\n",
    "        # If only one group is present, remove the 'Group ID' column\n",
    "        if len(new_dm_df['Group ID'].unique()) == 1:\n",
    "            new_dm_df = new_dm_df.drop(columns=['Group ID'])\n",
    "\n",
    "        # Create a new DecisionMatrix instance with modified attributes\n",
    "        new_self = DecisionMatrix(\n",
    "            metrics_df=new_dm_df,\n",
    "            objectives=self.objectives,\n",
    "            alt_cols=self.alt_cols,\n",
    "            crit_cols=self.crit_cols,\n",
    "            weights=self.weights,\n",
    "            group_cols=self.group_cols,\n",
    "            crit_cats=self.crit_cats,\n",
    "            group_weights=self.group_weights,\n",
    "        )\n",
    "        \n",
    "        return new_self\n",
    "    \n",
    "    def group_weighted_rescale_criteria(self):\n",
    "        \"\"\"\n",
    "        Rescale criteria values by applying group weights.\n",
    "\n",
    "        Returns:\n",
    "        - DecisionMatrix: A new instance of DecisionMatrix with rescaled criteria values and without group attributes.\n",
    "        \"\"\"\n",
    "        dm_df = self.dm_df.copy()\n",
    "        \n",
    "        # Ensure there are group columns and group weights defined\n",
    "        if not self.group_cols or not self.group_weights:\n",
    "            raise ValueError(\"Group columns or group weights not defined.\")\n",
    "        \n",
    "        # Iterate through each group and rescale criteria values\n",
    "        for group_col in self.group_cols:\n",
    "            group_weight_df = self.group_weights[group_col]\n",
    "            \n",
    "            for idx, row in group_weight_df.iterrows():\n",
    "                group = row[group_col]\n",
    "                weight = row['Weight']\n",
    "                group_mask = (dm_df[group_col] == group)\n",
    "                \n",
    "                for crit_col in self.crit_cols:\n",
    "                    dm_df.loc[group_mask, crit_col] *= weight\n",
    "\n",
    "        # Drop the group columns as they are no longer needed\n",
    "        dm_df = dm_df.drop(columns=self.group_cols)\n",
    "\n",
    "        # Create a new DecisionMatrix instance with modified attributes, excluding group columns and weights\n",
    "        new_self = DecisionMatrix(\n",
    "            metrics_df=dm_df,\n",
    "            objectives=self.objectives,\n",
    "            alt_cols=self.alt_cols,\n",
    "            crit_cols=self.crit_cols,\n",
    "            weights=self.weights,\n",
    "            group_cols=[],  # Remove group columns\n",
    "            crit_cats=self.crit_cats,\n",
    "            group_weights={},  # Remove group weights\n",
    "        )\n",
    "        \n",
    "        return new_self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to filter a DataFrame based on conditions\n",
    "def filter_dataframe(df, filter_conditions=None, derived_columns=None, base_cols=None):\n",
    "    \"\"\"\n",
    "    This function filters a DataFrame based on provided conditions and calculates derived columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame.\n",
    "    - filter_conditions (dict): A dictionary specifying filtering conditions for columns.\n",
    "    - derived_columns (dict): A dictionary specifying derived columns and their functions.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_df (pandas.DataFrame): The filtered DataFrame based on conditions and derived columns.\n",
    "    - boolean_df (pandas.DataFrame): A boolean DataFrame indicating whether values satisfy conditions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy of the input DataFrame\n",
    "    filtered_df = df.copy()\n",
    "    unfiltered_df = df.copy()\n",
    "    \n",
    "    # If conditions or derived columns are not provided, initialize them as empty dictionaries\n",
    "    if filter_conditions is None:\n",
    "        filter_conditions = {}\n",
    "    \n",
    "    if derived_columns is None:\n",
    "        derived_columns = {}\n",
    "\n",
    "    # Calculate and add derived columns to the filtered DataFrame\n",
    "    if derived_columns:\n",
    "        for new_col, function in derived_columns.items():\n",
    "            filtered_df[new_col] = function(df)\n",
    "            unfiltered_df[new_col] = function(df)\n",
    "\n",
    "    # Create a boolean DataFrame to track conditions satisfaction\n",
    "    if base_cols:\n",
    "        boolean_df = df[base_cols].copy()\n",
    "    else:\n",
    "        boolean_df = df.copy()\n",
    "    \n",
    "    # Apply filtering conditions and update boolean DataFrame accordingly\n",
    "    if filter_conditions:\n",
    "        for col, cond in filter_conditions.items():\n",
    "            \n",
    "            if isinstance(cond, list):\n",
    "                # Filter data based on whether column values are equal to the provided value\n",
    "                filtered_df = filtered_df[filtered_df[col] == cond['equal']]\n",
    "                boolean_df[col] = unfiltered_df[col] == cond['equal']\n",
    "            elif 'equal' in cond:\n",
    "                # Filter data based on whether column values are equal to the provided value\n",
    "                filtered_df = filtered_df[filtered_df[col].isin(cond['equal'])]\n",
    "                boolean_df[col] = unfiltered_df[col].isin(cond['equal'])\n",
    "            elif 'in' in cond:\n",
    "                # Filter data based on whether column values are in the provided list\n",
    "                filtered_df = filtered_df[filtered_df[col].isin(cond['in'])]\n",
    "                boolean_df[col] = unfiltered_df[col].isin(cond['in'])\n",
    "            elif 'greater' in cond:\n",
    "                # Filter data based on whether column values are greater than the provided value\n",
    "                filtered_df = filtered_df[filtered_df[col] > cond['greater']]\n",
    "                boolean_df[col] = unfiltered_df[col] > cond['greater']\n",
    "            elif 'less' in cond:\n",
    "                # Filter data based on whether column values are less than the provided value\n",
    "                filtered_df = filtered_df[filtered_df[col] < cond['less']]\n",
    "                boolean_df[col] = unfiltered_df[col] < cond['less']\n",
    "            elif 'range' in cond:\n",
    "                # Filter data based on whether column values are within the provided range\n",
    "                lower, upper = cond['range']\n",
    "                filtered_df = filtered_df[(filtered_df[col] >= lower) & (filtered_df[col] <= upper)]\n",
    "                boolean_df[col] = (unfiltered_df[col] >= lower) & (unfiltered_df[col] <= upper)\n",
    "\n",
    "    # Drop derived columns from the final filtered DataFrame\n",
    "    if derived_columns:\n",
    "        filtered_df = filtered_df.drop(derived_columns.keys(), axis=1)\n",
    "     \n",
    "    return filtered_df, boolean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
