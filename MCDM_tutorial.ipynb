{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this in the CLIMADA environment and if you encounter any problems run !pip uninstall pyrepo-mcda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required package\n",
    "\n",
    "!pip install pyrepo-mcda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Creating the data frame metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the enities object to investigate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Defines the entity and hazard set to be used\n",
    "# Choose the two following options for the file_str variable, begin with CLIMADA_DEMO:\n",
    "# 'CLIMADA_DEMO' - CLIMADA demo entity and hazard set TC  (Does not work for Part 4 – Groups)\n",
    "# 'CanTho_PLFL' - Can Tho, Vietnam and flood hazard\n",
    "\n",
    "file_str = 'CLIMADA_DEMO'   # or 'CLIMADA_DEMO'  'CanTho_PLFL'\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load entitites and hazards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.entity import Entity\n",
    "from climada.util.constants import ENT_DEMO_TODAY, ENT_DEMO_FUTURE, HAZ_DEMO_H5\n",
    "from climada.util.api_client import Client\n",
    "from climada.hazard import Hazard\n",
    "\n",
    "from MCDM.utils import CURRENT_YEAR, FUTURE_YEAR\n",
    "import copy\n",
    "\n",
    "\n",
    "## Entities and hazards containers\n",
    "# Entities should be defined in the following way:\n",
    "#       1) with a key refering to a reference name, example 'Assets', 'People', 'Infrastructure', or even 'Data_Provider_1' and 'Data_Provider_2'\n",
    "#       2) and a value being the entity object for the current and future year\n",
    "# Example: ent_dict = {'Assets': {'today': Entity(), 'future':Entity()},\n",
    "#                     'People': {'today': Entity(), 'future':Entity()}},\n",
    "#                     'Infrastructure': {'today': Entity(), 'future':Entity()}}\n",
    "\n",
    "# Parameters\n",
    "grwth_rate_dict = {'People': 0.02, 'Assets': 0.02 } # growth rate for the future exposure data\n",
    "\n",
    "# Load the entities and hazards\n",
    "if file_str == 'CLIMADA_DEMO':\n",
    "    ## Entities\n",
    "    ent_dict = {'Assets': {'today': Entity.from_excel(ENT_DEMO_TODAY), 'future':Entity.from_excel(ENT_DEMO_FUTURE)}}\n",
    "    ## Hazards\n",
    "    haz_dict = {'TCs': {'today': Hazard.from_hdf5(HAZ_DEMO_H5), 'future': Hazard.from_hdf5(HAZ_DEMO_H5)}}\n",
    "    haz_dict['TCs']['future'].intensity *= 1.5 # double the intensity of the future hazard\n",
    "\n",
    "\n",
    "elif file_str == 'CanTho_PLFL':\n",
    "\n",
    "    ## Entities\n",
    "    # Current exposure data - Assets and People\n",
    "    ent_dict=   {'Assets': {'today': Entity.from_excel('Data/Entities/entity_TODAY_CanTho_PLFL_Assets.xlsx')},\n",
    "                'People': {'today': Entity.from_excel('Data/Entities/entity_TODAY_CanTho_PLFL_People.xlsx')}\n",
    "                }\n",
    "    # Future exposure data - Assets\n",
    "    ent_dict['Assets']['future'] = copy.deepcopy(ent_dict['Assets']['today'])\n",
    "    ent_dict['Assets']['future'].exposures.gdf.value *= (1+grwth_rate_dict['Assets'])**(FUTURE_YEAR-CURRENT_YEAR) # increase the value of the future exposure data given the growth rate\n",
    "    # Future exposure data - People\n",
    "    ent_dict['People']['future'] = copy.deepcopy(ent_dict['People']['today'])\n",
    "    ent_dict['People']['future'].exposures.gdf.value *= (1+grwth_rate_dict['People'])**(FUTURE_YEAR-CURRENT_YEAR) \n",
    "\n",
    "    ## Hazards\n",
    "    # API client\n",
    "    client = Client()\n",
    "    # Hazards\n",
    "    haz_dict = {'river_flood': {'today': client.get_hazard(hazard_type='river_flood', properties={'country_iso3alpha': 'VNM', 'climate_scenario': 'historical'}),\n",
    "                                'future': client.get_hazard(hazard_type='river_flood', properties={'country_iso3alpha': 'VNM', 'climate_scenario': 'rcp26', 'year_range': '2030_2050'})\n",
    "                                }\n",
    "                }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genereate the metrics data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCDM.utils import generate_metrics, RISK_FNCS_DICT # Import the risk functions dictionary (default risk functions are defined in the utils.py file)\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "# Check if the file exists\n",
    "try:\n",
    "    # Load previous metrics dataframe\n",
    "    metrics_df = pd.read_csv(f'Data/Metrics/{file_str}.csv')\n",
    "except:\n",
    "    #%% Generate metrics dataframe\n",
    "    metrics_df = generate_metrics(haz_dict, ent_dict, risk_fncs_dict = RISK_FNCS_DICT, file_output = file_str)\n",
    "\n",
    "    # Add additional fictive metrics to the dataframe - APPROV and FEAS\n",
    "    temp_df = pd.DataFrame(metrics_df['measure'].unique(), columns=['measure'])\n",
    "    temp_df['approv'] = [np.random.randint(1, 5) for _ in range(len(temp_df))]\n",
    "    temp_df['feas'] = np.random.rand(len(temp_df))\n",
    "    extra_metrics_df = pd.merge(metrics_df, temp_df, on='measure')\n",
    "\n",
    "# Clear the cell output to avoid output from the print statement when calling the cost-benefit calculation  \n",
    "# However, if intrested in the output, comment the following line\n",
    "clear_output()\n",
    "\n",
    "# Print the first few rows of the dataframe\n",
    "print(f'Metrics in the {file_str} file')\n",
    "print('---------------------------')\n",
    "print(tabulate(metrics_df.head(), headers='keys', tablefmt='psql'))\n",
    "# Get all the columns of the dataframe ben_ or bcr_ or npv_ + RISK_FNCS_DICT.keys() + ent_dict.keys()\n",
    "all_crit_cols = [col for col in metrics_df.columns if 'ben_' in col or 'bcr_' in col or 'npv_' in col or 'approv' in col or 'cost' in col or 'feas' in col]\n",
    "print(f'The criteria columns of the metrics dataframe are: \\n{all_crit_cols}')\n",
    "print('---------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description metrics – Criteria of choice**\n",
    "\n",
    "| Metric            | Description                                                         | Objective | Example Utility |\n",
    "|-------------------|---------------------------------------------------------------------|-----------|-----------------|\n",
    "| cost_Assets       | Discounted cost of the measure given by entity named \"Assets\"                          | Minimize  |                 |\n",
    "| ben_aai_Assets    | Averted risk in comparison to no measure, based on avg. annual impact             | Maximize  | Identifies cost-effective measures. Usefule for excluding, i.e., filtering, non-cost-efficient measures.|\n",
    "| bcr_aai_Assets    | Benefit-to-cost ratio, based on avg. annual impact                  | Maximize  |                 |\n",
    "| npv_aai_Assets    | Total NPV of risk, with measure, based on avg. annual impact        | Minimize  | Enables identification of intolerable risk levels, such as assets or populations remaining at risk. |\n",
    "| ben_rp250_Assets  | Averted risk in comparison to no measure, based on 250-year return period         | Maximize  | Highlights measures reducing extreme risk |\n",
    "| bcr_rp250_Assets  | Benefit-to-cost ratio, based on 250-year return period              | Maximize  |                 |\n",
    "| npv_rp250_Assets  | Total NPV of risk, with measure, based on 250-year return period    | Minimize  |                 |\n",
    "| approv            | Criteria values representing public approval                        | Maximize  |                 |\n",
    "| feas              | Criteria values representing feasibility                            | Maximize  |                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Ranking the alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the decision matrix object and rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCDM.DecisionMatrix import DecisionMatrix  # Import DecisionMatrix module\n",
    "\n",
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "alt_cols = ['measure'] # Columns in metrics_df that contains the alternatives\n",
    "crit_cols = [col for col in all_crit_cols if 'bcr' not in col and 'npv' not in col] # Columns in metrics_df that contains the criteria\n",
    "objectives = {crit: -1 if 'cost' in crit else 1 for crit in crit_cols} # Dictionary of objectives\n",
    "weights = {} # Dictionary of weights. Default is equal for all criteria\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "\n",
    "# Initialize the decision matrix object\n",
    "dm = DecisionMatrix(metrics_df=metrics_df, objectives=objectives, alt_cols=alt_cols, crit_cols=crit_cols)\n",
    "\n",
    "# Print the alternatives\n",
    "print('The available alternatives are:')\n",
    "print('---------------------------')\n",
    "print(tabulate(dm.alternatives_df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Plot the criteria weights\n",
    "dm.plot_criteria()\n",
    "\n",
    "# Rank the alternatives\n",
    "ranks_output = dm.calc_rankings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the rankings only for the individual criteria, excluding the MCDM rankings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The performance of the alternatives based on each criteria is:')\n",
    "print('---------------------------')\n",
    "# Print the rankings - Criteria\n",
    "ranks_output.print_rankings(rank_type='criteria')\n",
    "print('---------------------------')\n",
    "print('Is any alternative clearly dominating the others?')\n",
    "# Plot the rankings -Criteria\n",
    "ranks_output.plot_ranks( alt_name_col = 'measure', rank_type='criteria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the rankings of the MCDM methods**\n",
    "\n",
    "\n",
    "\n",
    "| Method (Full Name)             | Approach & Application                                                                                                    | Decision Maker's Risk Profile                                                                                                                      |\n",
    "|--------------------------------|----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Simple Additive Weighting (SAW) | Additive weighting: SAW simply adds up the normalized values for each criterion, after multiplying them by their respective weights. This method is straightforward and works well when all criteria are well-understood and can be quantifiably expressed, making it an attractive choice for decision-makers who prefer clarity and simplicity in their evaluation process. | Ideal for decision-makers who value straightforward evaluations and are comfortable with decisions where the criteria are well-understood and quantifiable. |\n",
    "| Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) | Distance-based evaluation: TOPSIS assesses alternatives by determining their proximity to the most desirable (ideal) scenario and their distance from the least desirable (anti-ideal) scenario. It suits decision-makers who aim for a balanced approach, seeking an alternative that performs well across all considered criteria, thereby reflecting a moderate aversion to unfavorable outcomes. | Suited for those who seek a balanced solution that is as good as possible across all criteria, showing a moderate aversion to outcomes that are far from the best possible scenario. |\n",
    "| VIKOR | Compromise solution: VIKOR seeks an alternative that provides the best compromise between the ideal and the least desirable outcomes across all criteria. It's particularly effective for decision-makers inclined towards caution, aiming to ensure that selected options do not deviate significantly from acceptable standards in any of the considered aspects. | Perfect for cautious decision-makers looking to minimize exposure to the worst outcomes in any criterion, ensuring no option is too far from an acceptable outcome. |\n",
    "| Copeland (Ensemble Approach) | Ensemble ranking: The Copeland method synthesizes insights from multiple MCDM methods by conducting pairwise comparisons among alternatives, culminating in a unified ranking. This method is especially useful for integrating diverse perspectives, thus reducing the impact of specific biases or limitations associated with individual decision-making frameworks. | This approach balances various risk profiles, integrating insights from multiple methods to reduce sensitivity to any one method's parameters or weights. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The performance of the alternatives given by the MCDM methods is:')\n",
    "print('---------------------------')\n",
    "# Print the rankings - MCDM methods\n",
    "ranks_output.print_rankings(rank_type='MCDM', sort_by_col='copeland')\n",
    "# Plot the rankings - MCDM methods\n",
    "ranks_output.plot_ranks(alt_name_col = 'measure', rank_type='MCDM', sort_by_col='copeland', transpose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customized ranking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MCDM ranking methods\n",
    "from pyrepo_mcda.mcda_methods import AHP, TOPSIS, SAW, VIKOR #  SPOTIS, ARAS, COCOSO, CODAS, COPRAS, CRADIS, EDAS, MABAC, MARCOS, MULTIMOORA, MULTIMOORA_RS, PROMETHEE_II, PROSA_C,, VMCM, WASPAS, VIKOR_SMAA\n",
    "from pyrepo_mcda.compromise_rankings import copeland, dominance_directed_graph, rank_position_method\n",
    "from pyrepo_mcda import distance_metrics as dists\n",
    "from pyrepo_mcda import normalizations as norms\n",
    "\n",
    "\n",
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Define the MCDM ranking methods\n",
    "mcdm_methods = {'AHP': AHP(), # Analytic Hierarchy Process default parameters\n",
    "          'Topsis': TOPSIS(), # Technique for Order Preference by Similarity to Ideal Solution default parameters\n",
    "          'Saw': SAW(), # Simple Additive Weighting default parameters\n",
    "          'Custom_Topsis': TOPSIS(normalization_method = norms.minmax_normalization, distance_metric = dists.euclidean) # Custom method with customized normalization and distance methdods\n",
    "    }\n",
    "\n",
    "# Define the compromised ranking function of the rank matrices\n",
    "comp_ranks = {'copeland': copeland,\n",
    "      }\n",
    "\n",
    "# Dictionary of derived columns and their functions\n",
    "derived_columns = {'bcr': lambda df: df['ben_aai_Assets']/df['cost_Assets']}\n",
    "\n",
    "# Apply a constraint to the decision matrix\n",
    "# You find the filter definition in the utils.py file in the function filter_df\n",
    "constraints = {'ben_aai_Assets': {'greater': 0},\n",
    "                 # 'cost_Assets': {'less': 5000000},\n",
    "                  'bcr': {'greater': 1} # Benefit-cost ratio greater than 1 (Given the derived column above, this is equivalent to the benefit being greater than the cost)\n",
    "                  }\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "\n",
    "# Calculate the rankings\n",
    "ranks_output = dm.calc_rankings( mcdm_methods, comp_ranks, constraints=constraints, derived_columns=derived_columns)\n",
    "clear_output()\n",
    "\n",
    "\n",
    "# Check if ranks_output has an attribute alt_exc_const_df\n",
    "if hasattr(ranks_output, 'alt_exc_const_df'):\n",
    "    # Print the alternatives that do not satisfy the constraints\n",
    "    print(\"Table below shows the excluded alternatives, i.e., not satifying constraints,\\nwhere True if particular constraint is satisfied and False if not.\", 2*\"\\n.\")\n",
    "    print(tabulate(ranks_output.alt_exc_const_df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Plot the rankings\n",
    "ranks_output.plot_ranks(disp_rnk_cols=[], rank_type='MCDM', sort_by_col='copeland', transpose=False, alt_name_col='measure')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 – Weight sensitivities and preferences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "crit_cols_dict = {'MONEY': ['cost_Assets','ben_aai_Assets', 'ben_rp250_Assets']} # Dictionary of criteria categories and their criteria columns\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "# Calculate the sensitivity of the rankings to the weights of the criteria\n",
    "sensitivity_df = dm.calc_imprt_sensitivity(crit_cols_dict=crit_cols_dict, mcdm_methods=mcdm_methods, comp_ranks=comp_ranks, alt_tag='measure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criteria categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision matrix object and include more criteria\n",
    "\n",
    "# categorize the criteria assets and people\n",
    "crit_cats = {'MONEY': ['ben_aai_Assets',  'ben_rp250_Assets', 'cost_Assets'],\n",
    "             'PEOPLE': ['ben_aai_People', 'ben_rp250_People'],\n",
    "             'OTHER': ['approv', 'feas']}\n",
    "\n",
    "\n",
    "# Initialize the decision matrix object\n",
    "dm = DecisionMatrix(metrics_df=metrics_df, objectives=objectives, alt_cols=alt_cols, crit_cols=crit_cols, crit_cats=crit_cats)\n",
    "\n",
    "# Plot the criteria weights\n",
    "dm.plot_criteria(group_by_category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Incorporating uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the uncertainty variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty variables\n",
    "import scipy as sp\n",
    "\n",
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Do not modify the function names, e.g, ent_today_func!!!\n",
    "\n",
    "# Uncertainty variable distributions\n",
    "unc_var_dist_dict = {\"x_ent\": sp.stats.uniform(0.7, 1),\n",
    "                     \"m_fut_cost\": sp.stats.norm(1, 0.1),\n",
    "                     \"x_haz_today\": sp.stats.uniform(1, 3),\n",
    "                     \"x_haz_fut\": sp.stats.uniform(1, 3)}\n",
    "\n",
    "# Base functions\n",
    "# Entity today has an uncertainty in the total asset value\n",
    "def ent_today_func(x_ent, ent_today_base=None, ent_fut_base=None, haz_today_base=None, haz_fut_base=None):\n",
    "    entity = copy.deepcopy(ent_today_base)\n",
    "    entity.exposures.ref_year = CURRENT_YEAR\n",
    "    entity.exposures.gdf.value *= x_ent\n",
    "    return entity\n",
    "\n",
    "# Entity in the future has a +- 10% uncertainty in the cost of all the adapatation measures\n",
    "def ent_fut_func(m_fut_cost, ent_today_base=None, ent_fut_base=None, haz_today_base=None, haz_fut_base=None):\n",
    "    entity = copy.deepcopy(ent_today_base)\n",
    "    entity.exposures.ref_year = FUTURE_YEAR\n",
    "    for meas in entity.measures.get_measure(haz_today_base.haz_type):\n",
    "        meas.cost *= m_fut_cost\n",
    "    return entity\n",
    "\n",
    "# The hazard intensity in the future is also uncertainty by a multiplicative factor\n",
    "def haz_today_func(x_haz_today, ent_today_base=None, ent_fut_base=None, haz_today_base=None, haz_fut_base=None):\n",
    "    haz = copy.deepcopy(haz_today_base)\n",
    "    haz.intensity = haz.intensity.multiply(x_haz_today)\n",
    "    return haz\n",
    "\n",
    "# The hazard intensity in the future is also uncertainty by a multiplicative factor\n",
    "def haz_fut_func(x_haz_fut, ent_today_base=None, ent_fut_base=None, haz_today_base=None, haz_fut_base=None):\n",
    "    haz = copy.deepcopy(haz_fut_base)\n",
    "    haz.intensity = haz.intensity.multiply(x_haz_fut)\n",
    "    return haz\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate the metrics data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCDM.utils import generate_unc_func_dist_dict\n",
    "\n",
    "# Creaate the uncertainty functions dictionary input variable\n",
    "unc_func_dist_dict = generate_unc_func_dist_dict(func_dict= {'ent_today': ent_today_func, 'ent_fut': ent_fut_func, 'haz_today': haz_today_func, 'haz_fut': haz_fut_func}, unc_var_dist_dict= unc_var_dist_dict)\n",
    "\n",
    "# Check if the file exists\n",
    "try:\n",
    "    # Load previous metrics dataframe\n",
    "    metrics_unc_df = pd.read_csv('Data/Metrics/{}.csv'.format(file_str + '_unc'))\n",
    "except:\n",
    "    #%% Generate metrics dataframe\n",
    "    if file_str == 'CLIMADA_DEMO':\n",
    "        n_samples = 100\n",
    "    else:\n",
    "        n_samples = 1 # You can increase the number of samples but very slow for the CanTho_PLFL case\n",
    "\n",
    "    # Generate the metrics dataframe\n",
    "    metrics_unc_df = generate_metrics(haz_dict, ent_dict, unc_func_dist_dict = unc_func_dist_dict, risk_fncs_dict = RISK_FNCS_DICT, n_samples= n_samples, future_year=FUTURE_YEAR, current_year=CURRENT_YEAR, file_output = file_str + '_unc')\n",
    "\n",
    "\n",
    "# Clear the cell output to avoid output froom the print statement in the cost-bebefit analysis.\n",
    "clear_output()\n",
    "\n",
    "# Print the first few rows of the dataframe\n",
    "print(\"\\n.\", \"Table below shows the first few rows of the dataframe with the uncertainty samples.\", 2*\"\\n.\")\n",
    "print(tabulate(metrics_unc_df.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate and display the ranks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Define the uncertainty variables\n",
    "unc_cols = [key for key in unc_var_dist_dict] # Columns in metrics_df that contains the uncertainty variables\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "\n",
    "# Initialize the decision matrix object\n",
    "dm_unc = DecisionMatrix(metrics_df=metrics_unc_df, objectives=objectives, alt_cols=alt_cols, crit_cols=crit_cols, unc_cols=unc_cols)\n",
    "\n",
    "# Rank the alternatives\n",
    "ranks_output_unc = dm_unc.calc_rankings()\n",
    "clear_output()\n",
    "\n",
    "# Print the sample dataframe\n",
    "print(\"\\n.\", \"Table below shows the dataframe with the unique uncertainty samples.\", 2*\"\\n.\")\n",
    "print(\"_\"*100)\n",
    "print(tabulate(dm_unc.unc_smpls_df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rankings\n",
    "ranks_output_unc.plot_rank_distribution(disp_rnk_col='copeland', alt_name_col='measure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at samples where each measure performs well and poor**\n",
    "\n",
    "*Note: This analysis can be enhanced by integrating with the 'unsequa' module to explore how ranking sensitivities and different \"scenarios\" — sets of uncertainty variables — affect the performance of each alternative, both positively and negatively.e*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top and bottom 5 alternatives for each measure\n",
    "for measure in ranks_output_unc.ranks_MCDM_df['measure'].unique():\n",
    "    # Filter the dataframe for the current measure\n",
    "    measure_df = ranks_output_unc.ranks_MCDM_df[ranks_output_unc.ranks_MCDM_df['measure'] == measure]\n",
    "    # Drop the Group ID column\n",
    "    measure_df.drop(columns='Group ID', inplace=True)\n",
    "\n",
    "    # Sort the filtered dataframe on the 'copeland' column\n",
    "    measure_df.sort_values(by='copeland', ascending=True, inplace=True)\n",
    "\n",
    "    # Print the top 5 alternatives\n",
    "    print(f\"The top 5 alternatives for the measure {measure} are:\")\n",
    "    print(tabulate(measure_df.head(5), headers='keys', tablefmt='psql'))\n",
    "\n",
    "    # Print the bottom 5 alternatives\n",
    "    print(f\"The bottom 5 alternatives for the measure {measure} are:\")\n",
    "    print(tabulate(measure_df.tail(5), headers='keys', tablefmt='psql'))\n",
    "\n",
    "    print('---------------------------')\n",
    "    print(\"\\n.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out specific samples to rank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Define the condition\n",
    "rank_filt = {'m_fut_cost': {'range': (1.0, 1.2)},\n",
    "               'x_haz_today': {'greater': 1.5}\n",
    "               }\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "# Rank the alternatives\n",
    "filt_ranks_output_unc = dm_unc.calc_rankings(rank_filt=rank_filt)\n",
    "\n",
    "# Clear the cell output to avoid output froom the print statement in the cost-bebefit analysis.\n",
    "clear_output()\n",
    "\n",
    "# Print the rankings\n",
    "filt_ranks_output_unc.print_rankings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derive (new) criteria as the conditional mean**  \n",
    "\n",
    "*This approach is useful for analyzing specific scenarios, i.e., sets of uncertainty variables.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Define the condition\n",
    "condition = {'m_fut_cost': {'greater': 1} # The future cost of the adaptation measures is greater than 1\n",
    "                  }\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "# Calculate the conditional mean based criteria\n",
    "dm_cond_unc_mean = dm_unc.mean_based_criteria(condition=condition)\n",
    "\n",
    "# Calculate the rankings\n",
    "rnks_cond_unc_mean = dm_cond_unc_mean.calc_rankings( mcdm_methods, comp_ranks)\n",
    "\n",
    "# Plot the rankings\n",
    "print(\"The plot below shows the rankings of the alternatives based on the conditional mean of the criteria.\", 2*\"\\n.\")\n",
    "rnks_cond_unc_mean.print_rankings(sort_by_col='copeland')\n",
    "rnks_cond_unc_mean.plot_ranks(sort_by_col='copeland', alt_name_col='measure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Considering Groups (Only works for file_str = 'CanTho_PLFL': Go back to Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you look at the entities exposure object, you will see that the exposure geodataframe has a description column \"admin1_info\"\n",
    "\n",
    "# Print the first few rows of the exposure geodataframe\n",
    "print(tabulate(ent_dict['Assets']['today'].exposures.gdf.head(), headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Print the unique set of groups in admin1_info\n",
    "print(\"The unique set of groups in the admin1_info column is:\")\n",
    "print(ent_dict['Assets']['today'].exposures.gdf.admin1_info.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calc the metrics for each group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the metrics dataframe but with the admin1_info column as a group column\n",
    "\n",
    "# Check if the file exists\n",
    "try:\n",
    "    # Load previous metrics dataframe\n",
    "    metrics_group_df = pd.read_csv('Data/Metrics/{}.csv'.format(file_str + '_group'))\n",
    "except:\n",
    "    #%% Generate metrics dataframe\n",
    "    metrics_group_df = generate_metrics(haz_dict, ent_dict, groups = ['admin1_info'], risk_fncs_dict = RISK_FNCS_DICT, future_year=FUTURE_YEAR, current_year=CURRENT_YEAR, file_output = file_str + '_group')\n",
    "\n",
    "# Filter out the 'ALL' group which is simply the the exposure data for the entire region\n",
    "metrics_group_df = metrics_group_df[metrics_group_df['admin1_info'] != 'ALL']\n",
    "# ALso filter out the 'unknown' group to make the graph more readable\n",
    "metrics_group_df = metrics_group_df[metrics_group_df['admin1_info'] != 'unknown']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the dm object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "# Define the internal group weights (default is equal if none is defined) which should sum to 1\n",
    "group_weights = {'admin1_info': {'Vĩnh Long': 0.7, 'Hau Giang': 0.3}}\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "\n",
    "# Initialize the decision matrix object\n",
    "dm_groups = DecisionMatrix(metrics_df=metrics_group_df, objectives=objectives, alt_cols=alt_cols, crit_cols=crit_cols,\n",
    "                           group_cols=['admin1_info'], group_weights= group_weights )\n",
    "\n",
    "# Print the groups\n",
    "print(2*'.\\n')\n",
    "print('The available groups and the internal group weights for the specific group are:')\n",
    "print('---------------------------')\n",
    "print(tabulate(dm_groups.group_weights['admin1_info'], headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calc ranks for each group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either look at the rankings of the alternatives for each group or the rankings of the groups themselves\n",
    "# Rank the alternatives\n",
    "ranks_output = dm_groups.calc_rankings()\n",
    "\n",
    "# Clear the cell output to avoid output froom the print statement in the cost-bebefit analysis.\n",
    "# However, if intrested in the output, comment the following line\n",
    "clear_output()\n",
    "\n",
    "# Print the rankings\n",
    "print('The performance of the alternatives for each group based on the criteria is:')\n",
    "ranks_output.print_rankings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot the groups to create new criteria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** User-modifiable parameters ***************\n",
    "\n",
    "group_by_category = True # Select True if the criteria should be grouped by category\n",
    "\n",
    "# *************** End of user-modifiable parameters ***************\n",
    "\n",
    "\n",
    "# Or you can create a new decision matrix object with the groups as alternatives and the criteria as the alternatives\n",
    "dm_piv = dm_groups.pivot_and_reweight_criteria(piv_col='admin1_info')\n",
    "\n",
    "# Plot the criteria weights\n",
    "dm_piv.plot_criteria(group_by_category=group_by_category)\n",
    "\n",
    "# Rank the groups\n",
    "ranks_output = dm_piv.calc_rankings()\n",
    "\n",
    "# Print the rankings\n",
    "ranks_output.plot_ranks(sort_by_col='copeland', alt_name_col='measure')\n"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
